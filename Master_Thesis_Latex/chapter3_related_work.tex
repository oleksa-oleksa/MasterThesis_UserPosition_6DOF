% !TeX spellcheck = en
\chapter{Related work}
\label{sec:related}
This chapter presents the overview of previous research in the field of the prediction of user position. It includes both approaches for 3-DoF and 6-DoF environment, focusing on time series methods, Kalman Filter and overview of different  Recurrent Neural Network architectures such as LSTM and GRU.  


\section{Time series methods}
\label{sec:related:timeseries}
HMDs now being more widely available to general users last years and the using of algorithms of head motion prediction has been an indispensable component even in 360-degree video streaming systems. A lot of previous approaches uses basic processing of head movement history to predict the future movement, such as simple average, linear regression, and weighted linear regression \cite{attention_saliency}. Work of \textit{Corbillon et al., 2017} calculates the region that receives from server the video data with a better quality than the remaining of part the video. With simple average researchers determine the distance to the center of viewpoint. The bit-rate of of the biggest part of the delivered video will be thus lower than the original full-quality video because video parts distant from the center will be encoded at low quality \cite{simple_average}.\\
The work of \textit{Duanmu et al., 2017} proposes prediction of the viewing direction for segment n + 1 through linear regression based on the past 30 view samples \cite{linreg1}. The 360 video is divided into twelve segments horizontally and into three vertically. Thus it is able to obtain the actual rates of the low-quality, medium-quality and the high-quality versions based on calculated position of a chunk n + 1 \cite{linreg1}.\\
Approach of \textit{Xie et al., 2017} uses user’s orientation in Euler angle and leverage Linear Regression model to do prediction \cite{linreg2}. The historical samples in window are used to apply Least Square Method and calculate the trends of head movements. The slope over yaw, pitch and roll is denoted and thus an estimated value of yaw, pitch and roll can be predicted using Linear Regression model \cite{linreg2}. 

Here LINGERG 3

\section{Kalman Filter}
\label{sec:related:kalman}

KF-based extrapolation are deemed to be robust against fast fluctuations, but suffer from susceptibility to noise sensory data \cite{delay_compensation_360}.

\section{Recurrent Neuronal Network}
\label{sec:related:deep}
In this section the network architectures of most relevant works in the field head motion prediction with RNNs are explained and discussed whether LSTM or GRU architecture is better for the actual problem presented in this thesis. As was mentioned in section \ref{sec:related:timeseries}, typical HMD computes user positions in 6-DoF by using its tracker module and data comes as time series with a sequential order. The structure of an input is crucial and needed to be followed in order to predict the next future step for a look-ahead time correctly. A sequence of inputs can be processed with Artificial Neural Network (ANN) called Recurrent Neural Network (RNN). Moreover, RNN can processes input with remembering its state while processing the next sequence of inputs. In the last decade, RNN algorithms have been adopted for motion prediction of 3D sequences. For example, the work of \textit{Crivellari et al., 2020} targets traces of short-term tourists in a foreign country and tries to predict the motion of people in the environment they never seen before. LSTM-based model is used thus for analyzing the tourists’ mobility patterns \cite{tourist_traces}. The work of \textit{Yang et al., 2020} proposes using of flashbacks on hidden states in RNNs to search past hidden states with high predictive power. Authors mentioned that their approach gives an ability to determine a specific Point of Interests (POIs) from user’s mobility trace stored as a sequence of check-ins in Based Social Networks (LBSNs). Exploring the dataset researchers found sparsity and incompleteness of input sequences and thus the sequential pattern is difficult to be captured by RNNs. They considered temporal distances between similar POIs by flashing back to the historical hidden states sharing a similar temporal context as the current one \cite{rnn_traces_hidden}. \\
%================================================
The authors \textit{Aykut et al., 2018} claims their research to be first work that applies deep learning for head motion prediction. The current three rotations in three dimensions the so-called Euler angles as well as past values thereof within a certain time window (W) used as input for the network \cite{delay_compensation_360}. The best results delivered when 20 last values for each orientation direction (W = 250 ms) were used \cite{delay_compensation_360}. Instead of the absolute orientation values \textit{Aykut et al., 2018} suggest for a goal of generalization for other datasets to subdivide the inputs into their respective orientation groups and compute their normalized differences \cite{delay_compensation_360}. The authors experimentally confirmed that Feed-forward Neural Network (FFN) indeed had difficulties to learn for different delays even after an architecture was extended with the present delay and injected into all NN nodes. The using of LSTM-based architectures \textit{Aykut et al., 2018} reasoned with feedback loop and ability to establish a way of memory and share weights over time \cite{delay_compensation_360}. Researchers used Adam optimization algorithm, the maximum number of epochs was set to 1000, early stopping technique (patience = 2, min. delta = 0) was used to avoid overfitting. Additionally, the learning rate was decreased by 70\% from initial value of 0.001 every 30 epochs. The batch size B was set to $2^{11}$. Rectified Linear Unit (ReLU) as activation function for the FFN layers used with LSTM \cite{delay_compensation_360}. Three different architecture were tried. In all variants an input for NN was subdivided into dimensions and normalized within time window W set to 250 ms with $\triangle$t = 25 ms. Thus the length of input vector is equal to 10. Final result obtained from each NN variant is a vector of length of 10 for each pan, tilt and roll dimension separately containing future prediction with LAT 1s and step of 0.1s. \\
Conducted by researchers experiments showed that the LSTM-based architecture leads to a significant improvement of the MAE and RMSE metrics. The best performance is achieved by the interleaved architecture of LSTM and dense FFN blocks \cite{delay_compensation_360}. The LSTM-based methods were compared also to widely used approaches like the Linear Regression and a Kalman Filter based optimal state estimate. Thus \textit{Aykut et al., 2018} demonstrated a substantial improvement of the deep predictor for latencies in the range of 0.1–0.9 s \cite{delay_compensation_360}.\\ 
%================================================
Next year \textit{Aykut et al., 2019} experimented in their work \cite{telepresence} with GRU model that belongs to the group of recurrent neural networks (RNN). Authors mentioned that they already achieved best performance for headmotion prediction with LSTM as described before. However they tried an usage of dense GRUs combined with convolutional components regarding that fact that GRU is computationally more efficient, as it has fewer parameters and states than LSTM units \cite{telepresence}. The GRU-CNN-based network also receives pan, tilt, and roll present and past values within the same W = 250ms for last 20 values. Network trained on the normalized differences instead of using of the absolute values as it was done in \cite{delay_compensation_360}. A convolution layer performs as low-pass filter and reduces the noise. The core of the network consists of an interleaved structure of six dense GRUs each with 30 nodes and subsequent convolution units (kernel size 30x30), which compute the most distinct features. Max pooling layer down-samples the output of the last convolution layer and keeps the most significant features. The last step is passing the results through dense FFN and inverse remapping to the absolute orientation values. The model also predicts whole sequence of orientation values with LAT 1s and step of 0.1s as in \cite{telepresence}. The number of epoch in training remains the same as in \cite{delay_compensation_360} but early-stopping technique has higher patience parameter and equal 10. Compared to \cite{delay_compensation_360} the batch size was reduced to $2^{9}$. The rest of model parameters remains the same as in previous work of \textit{Aykut et al., 2018}. Authors said that proposed GRU-CNN-based network is able to improve the MAE and RMSE compared to all Kalman Filter and described above LSTM-CNN methods, especially for larger delays \cite{telepresence}. \\
%================================================
Researchers \textit{Karim et al., 2018} developed long short term memory fully convolutional network (LSTM-FCN). In the proposed models, the fully convolutional block is augmented by an LSTM block followed by dropout. The fully convolutional block consists of three stacked temporal convolutional blocks with filter sizes of 128, 256, and 128 respectively \cite{lstm_fcn}. Each convolutional block is identical to the convolution block in the CNN architecture proposed by \textit{Wang et al., 2018} in their work \cite{timeseries_scratch}. This means the basic block is a convolutional layer followed by a batch normalization layer and a ReLU activation layer. The convolution operation is fulfilled by three 1-D kernels with the sizes {8, 5, 3} without striding \cite{timeseries_scratch}. \textit{Wang et al., 2018} excluded in their FCN any pooling operation to prevent overfitting. Batch normalization helps to reduce generalization error. Global average pooling layer reduces the number of weights. Softmax layer produces the final labels \cite{timeseries_scratch}. The LSTM block, comprising of either a general LSTM layer or an Attention LSTM layer, is followed by a dropout. The output of the global pooling layer from FCN output and the LSTM block is concatenated and passed onto a softmax classification layer \cite{lstm_fcn}.\\
The important detail is that FCN block and LSTM block perceive the same time series input in two different views. If there is a time series of length N, the fully convolutional block will receive the data in N time steps \cite{lstm_fcn}. \textit{Karim et al., 2018} sends additionally the time series input into a dimension shuffle layer. Thus LSTM block receives transformed input having N variables with a single time step. Authors say that without the dimension shuffle, the performance of the LSTM block is significantly reduced due to the rapid overfitting of small short-sequence \cite{lstm_fcn}.\\
%================================================
In work of \textit{Chang et al., 2020} LSTM-based model is proposed to predict displacement of positions in each timestamp given measured acceleration and Euler angles from sensor signals \cite{6DoF_Tracking}. In addition to standard LSTM networks, they also use bidirectional LSTM (Bi-LSTM) networks, which is stacked two LSTM networks in forward and backward directions. Standard LSTM networks can only consider the past information and Bi-LSTM networks can capture both past and future information by two opposite temporal order in hidden layers \cite{6DoF_Tracking}. Authors predicted first displacement $x_{t_2} - x_{t_1}$ over the time interval $[t1, t2]$ and used it to obtain the position. Experimentally, authors found that the basic LSTM performs the best comparing to Bi-LSTM and Temporal Convolutional Network. Thus LSTM network with 3 layers used in this paper as the main structure.\\
%================================================
The paper \cite{action_recognition} also aims for action recognition using sensor signals from HMD. This approach presents another combination of of gated recurrent unit and additional model. Convolutional Auto-Encoder (CAE) model in a clustering fashion learns discriminative feature representation and helps to conquer difficulty of recognizing similar actions. As in the work \cite{6DoF_Tracking}, a deep sequential model learns the temporal representations and predicts the displacement of positions with acceleration and Euler angle to reduce error accumulation. Similar to \cite{6DoF_Tracking}, researches also used additionally a bidirectional LSTM (Bi-LSTM) network. The usage of CAE is proposed as a feature extraction model for feature representation of action signals and is composed of an encoder and decoder \cite{action_recognition}. The encoder contains two 2D convolutional layers with a kernel of size 3 × 1 with the stride of 1. The decoder contains two 2D transposed convolutional layers with the same kernel size and stride. The bottleneck is three feed-forward fully-connected layers with neurons of 1024, 128, and 1024, respectively. The tanh function is used as the activation function between the convolution layer and the fully connected layer \cite{action_recognition}. Input contains body acceleration, gravity acceleration, gyroscope, and quaternion with dimension equal to 26. The action signal is divided into segments of 25 timestamps by stride-1 sliding windows In this approach an action is performed and recorded separately and ground-truth labels was assigned. Then, the signals of each action with ground-truth labeling are used as input to CAE model for feature extraction by sliding windows \cite{action_recognition}. Authors mentioned a representation of a signal data by the latent vector in the low-dimensional space after using the CAE model. The latent vector then will be clustered by K-Means Clustering so that centroids are referred to as motion bases in a model. For action tracking with LSTM, the displacement in each timestamp was predicted first and then added to its previous location, instead of predicting each position directly \cite{action_recognition}. Similar as in work \cite{6DoF_Tracking} the 3-layered LSTM model performed better compared to Bi-LSTM. Authors said that the possible reason could be the short-term correlation of human actions in their dataset and that Bi-LSTM with its complicated model structure is rather suitable for long-term actions \cite{action_recognition}.\\
%================================================
The paper of \textit{Chung et al., 2014} should be noted separately in the end of related works review because it provides an interesting compassion and evaluation of the performance of recurrent units LSTM and GRU on sequence modeling. Authors mentioned the ability of LSTM to keep the existing memory via the introduced gates and thus to detect an important feature from an input sequence at early stage, to easily carry this information (the existence of the feature) over a long distance, hence, capturing potential long-distance dependencies \cite{empirical_evaluation}. The GRU takes linear sum between the existing state and the newly computed state similar to the LSTM but does not have any mechanism to control the degree to which its state is exposed, but exposes the whole state each time \cite{empirical_evaluation}. \textit{Chung et al., 2014} emphasize the fact that any important feature, decided by either the forget gate of the LSTM unit or the update gate of the GRU, will not be overwritten but be maintained as it is \cite{empirical_evaluation}. LSTM unit controls the amount of the new memory content and does not have any separate control of the amount of information flowing from the previous time step. The GRU differs and controls the information flow from the previous activation when computing the new and does not independently control the amount of the candidate activation being added via update gate \cite{empirical_evaluation}. The experiments provided in this work clearly indicate the advantages of the gating units over the more traditional recurrent units. \textit{Chung et al., 2014} mentioned that with dataset they used GRU unit outperformed LSTM unit. But they suggest that the choice of the type of gated recurrent unit may depend heavily on the dataset and corresponding task \cite{empirical_evaluation}. Thus in section \ref{sec:design:dataset:explor} of chapter ``Data and Model'' the data exploration of the obtained from HMD Microsoft HoloLend is done in order to understand the dataset before the beginning with a development of model architecture. 