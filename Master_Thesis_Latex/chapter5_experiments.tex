% !TeX spellcheck = en
\chapter{Implementation and experiments}
\label{sec:imp}

Here some code for my super neural network. 
The artificial neural networks discussed in this text are only remotely related to their biological counterparts. In this section we will briefly describe those characteristics of brain function that have inspired the development of artificial neural networks.

 
\begin{lstlisting}[caption={StudentFactory},captionpos=b]
class StudentFactory(DjangoModelFactory):
	class Meta:
		model = Student
	student_card = factory.SubFactory(StudentCardFactory)
	first_name = factory.Faker('first_name')
	second_name = factory.Faker('last_name')
\end{lstlisting}

\begin{wrapfigure}{l}{0.55\textwidth}
	\fbox{\includegraphics[width=0.5\textwidth]{gfx/LSTM-FCN.png}}
	\caption{LSTM Fully Convolutional Networks for Time Series Classification}
	\label{fig:nn1}
\end{wrapfigure}

You might already know that you want to apply an established theory or set of theories to a specific context (for example, reading a literary text through the lens of critical race theory, or using social impact theory in a market research project). 

\section{Implementation}
\label{sec:imp:programming}

\subsection{Unity application}
\label{sec:imp:programming:unity}
An application was developed in Unity with the Mixed Reality Toolkit and deployed on HoloLens 2. The goal of the application is to obtain the user position and orientation during the time a user wears a HMD. As this research aims to find an approach to reduce the M2P latency during rendering and delivering the volumetric content to end-user device, the volumetric animated object was placed three meters ahead of the user in Unity application. Users wearing HMD thus were asked to look on animated volumetric object and to move freely inside the laboratory space.\\
In Unity, the Main Camera is always the primary stereo rendering component attached to HMD and it is rendering everything the user sees \footnote{https://docs.microsoft.com/en-us/windows/mixed-reality/develop/unity/camera-in-unity}. The starting position of the user is set to $(0, 0, 0)$ during the application launch and the Main Camera tracks movement of the user's head. Although HoloLens allows to build a world-scale application, the room-scale experience was selected for spatial coordinate system. This lets users to walk around within the 5-meter boundary what is quite enough for user's movements inside the laboratory space and simultaneously watching the volumetric video object. 

\subsection{LSTM Model}
\label{sec:imp:programming:model}

\section{Experiments}
\label{sec:imp:experiments}


\section{Evaluation metrics}
\label{sec:imp:eval}


\begin{figure}
	\centering
	\fbox{\includegraphics[width=1\textwidth]{gfx/LSTM-FCN.png}}
	\caption{LSTM FCN WRAP}
	\label{fig:nn2}
\end{figure}


\section{Results}
\label{sec:imp:results}
