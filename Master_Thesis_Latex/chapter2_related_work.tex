% !TeX spellcheck = en
\newpage
\section{Related works}
\label{sec:related}
This section presents the overview of previous research in the field of the prediction of user position and focuses on time series methods using different RNN architectures such as LSTM and GRU.


\subsection{Traditional prediction algorithms}
\label{sec:related:timeseries}
A lot of previous approaches uses basic processing of head movement history to predict the future movement, such as simple average, linear regression, and weighted linear regression \cite{attention_saliency}. Work of \textit{Corbillon et al., 2017} determines the distance to the center of viewpoint with simple average and calculates the region that receives from server the video data with a better quality than the remaining of part the video \cite{simple_average}.\\ The work of \textit{Duanmu et al., 2017} proposes prediction of the viewing direction for segment n + 1 through linear regression based on the past view segments \cite{linreg1}. Approach of \textit{Xie et al., 2017} uses user’s orientation in Euler angle and leverage Linear Regression model to apply Least Square Method and to calculate the trends of head movements \cite{linreg2}. The work \cite{linreg3} proposes to receive from a server only the data of covered by user's viewport. At each point of time, the client requests data which would be played in the future. \textit{Taghavi et al., 2017} use Weighted Linear Regression to predict the next viewport based on window with the latest viewport samples. Researchers mentioned that a client can continue playback of at least a low-quality version of the video when the download time of next video portion varies \cite{linreg3}.

Analysis done by \textit{Qian et al., 2016} indicates that at least in the short term, viewers’ head movement can be predicted with accuracy > 90\% by even using simple methods such as linear regression \cite{cellular_opt}. The different approaches were compared such as computing the average value, using the linear regression with all samples and with weighted linear regression with recent samples. With weighted linear regression the average prediction accuracy for short-term values was higher than 90\% across all users. However in the longer term it is more difficult to achieve the good result and the average accuracy drops to about 70\% \cite{cellular_opt}.

A method to apply saliency algorithms to VR video viewings was presented by \textit{Aladagli et al., 2017} in work \cite{predicting_360}. Cross-correlation analysis used for measuring the relationship between the predicted fixation sequences and the recorded head movements \cite{predicting_360}. Based on works mentioned above, \textit{Nguyen et al., 2018} proposed panoramic saliency algorithm in order to learn the dependence of head tracking logs and saliency maps from the past video frames.

\subsection{Recurrent Neuronal Networks}
\label{sec:related:deep}
As was explained above, traditional prediction algorithms can not be used straightforward on a new media content in 6-DoF VR Applications. The user position and rotation data is coming as time series with a sequential order that is crucial to be followed in order to predict correctly the next future step for a look-ahead time. A sequence of inputs can be processed with Artificial Neural Network (ANN) called Recurrent Neural Network (RNN). Moreover, RNN can processes input with remembering its state while processing the next sequence of inputs. It is known that standard RNN has difficulties to learn long-term dependencies with gradient descent \cite{rnn_difficults}. Though RNN can robustly store information, it yields a problem of vanishing gradient that make leaning difficult \cite{rnn_difficults}. In the last decade, RNN algorithms have been adopted for motion prediction of 3D sequences with long-term dependencies taken into account. For example, the work of \textit{Crivellari et al., 2020} targets traces of tourists in a foreign country and tries to predict the motion of people in the environment they never seen before. LSTM-based model is used thus for analyzing the tourists’ mobility patterns \cite{tourist_traces}.

The authors \textit{Aykut et al., 2018} claims their research to be first work that applies deep learning for head motion prediction. The authors experimentally confirmed that Feed-forward Neural Network (FFN) indeed had difficulties to learn for different delays. The decision to use LSTM-based architectures \textit{Aykut et al., 2018} reasoned with feedback loop and ability to establish a way of memory and share weights over time \cite{delay_compensation_360}. Conducted by researchers experiments showed that the LSTM-based architecture leads to a significant improvement of the MAE and RMSE metrics \cite{delay_compensation_360}. The LSTM-based methods were compared also to widely used approaches like the Linear Regression and a Kalman Filter based optimal state estimate. Thus \textit{Aykut et al., 2018} demonstrated a substantial improvement of the deep predictor for latencies in the range of 0.1–0.9 s \cite{delay_compensation_360}.

Next year \textit{Aykut et al., 2019} experimented in their work \cite{telepresence} with GRU model that belongs to the group of recurrent neural networks (RNN). Authors considered GRU usage because it is computationally more efficient, as it has fewer parameters and states than LSTM units \cite{telepresence}. Proposed in the research GRU-based network is able to improve the MAE and RMSE compared to mentioned above LSTM model, especially for larger delays \cite{telepresence}. 

Researchers \textit{Karim et al., 2018} developed long short term memory fully convolutional network (LSTM-FCN). In the proposed models, LSTM block is augmented by an fully convolutional block \cite{lstm_fcn} identical to the convolution block in the CNN architecture proposed by \textit{Wang et al., 2018} in their work \cite{timeseries_scratch}. \textit{Karim et al., 2018} tried to reduce the rapid model's overfitting by transformation of input to have N variables with a single time step \cite{lstm_fcn}.

In work of \textit{Chang et al., 2020} used in addition to standard LSTM networks also bidirectional LSTM (Bi-LSTM) networks, which is stacked two LSTM networks in forward and backward directions. Standard LSTM networks can only consider the past information and Bi-LSTM networks can capture both past and future information by two opposite temporal order in hidden layers \cite{6DoF_Tracking}. Experimentally, authors found that the basic LSTM performs the best comparing to Bi-LSTM and Temporal Convolutional Network  \cite{6DoF_Tracking}.

GRU Model and additionally a bidirectional LSTM (Bi-LSTM) network are used for action recognition based on sensor signals from HMD in work \cite{action_recognition}. Similar as in work \cite{6DoF_Tracking} the LSTM model performed better compared to Bi-LSTM and a GRU outperformed both models. Authors said that the possible reason could be the short-term correlation of human actions in their dataset and that Bi-LSTM with its complicated model structure is rather suitable for long-term actions \cite{action_recognition}. The experiments provided in these works clearly indicate that GRU unit can outperform LSTM unit. However, researches suggested that the choice of the RNN model can depend heavily on the dataset and corresponding task \cite{empirical_evaluation}.