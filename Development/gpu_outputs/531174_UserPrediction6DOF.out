INFO:root:LSTM Pure PyTorch: hidden_dim: 32, n_epochs: 740, batch_size: 4096.
INFO:root:Trace path: data/flipped/1556.csv
INFO:root:Prediction window = 100.0 ms
INFO:root:MAE position = 0.06303895060221354
INFO:root:MAE rotation = 2.1579301269150597
INFO:root:RMSE position = 0.1311813
INFO:root:RMSE rotation = 2.996221418661831
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/opt/UserPrediction6DOF/__main__.py", line 45, in <module>
    APPLICATION.run()
  File "/opt/UserPrediction6DOF/application.py", line 91, in run
    self.run_lstm()
  File "/opt/UserPrediction6DOF/application.py", line 138, in run_lstm
    runner.run()
  File "/opt/UserPrediction6DOF/runners.py", line 394, in run
    'euc_dists_lstm_{}_{}ms.npy'.format(basename, int(w * 1e3))), euc_dists)
  File "<__array_function__ internals>", line 6, in save
  File "/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py", line 525, in save
OSError: [Errno 30] Read-only file system: './results/tabular/distances/euc_dists_lstm_1556_100ms.npy'
-------------------------------------------------------------------------
-------------------------------------------------------------------------
X_train (71999, 11), X_val (24000, 11), X_test(24000, 11), y_train (71999, 7), y_val (24000, 7), y_test (24000, 7)
[1/740] Training loss: 5.1301	 Validation loss: 2.9080
[2/740] Training loss: 4.9562	 Validation loss: 2.7968
[3/740] Training loss: 4.7804	 Validation loss: 2.6810
[4/740] Training loss: 4.5945	 Validation loss: 2.5567
[5/740] Training loss: 4.3934	 Validation loss: 2.4224
[10/740] Training loss: 3.2153	 Validation loss: 1.6852
[15/740] Training loss: 2.0842	 Validation loss: 1.0598
[20/740] Training loss: 1.2533	 Validation loss: 0.6377
[25/740] Training loss: 0.7629	 Validation loss: 0.4162
[30/740] Training loss: 0.5110	 Validation loss: 0.3415
[35/740] Training loss: 0.3780	 Validation loss: 0.3167
[40/740] Training loss: 0.2897	 Validation loss: 0.2928
[45/740] Training loss: 0.2224	 Validation loss: 0.2687
[50/740] Training loss: 0.1716	 Validation loss: 0.2416
[55/740] Training loss: 0.1339	 Validation loss: 0.2154
[60/740] Training loss: 0.1061	 Validation loss: 0.1916
[65/740] Training loss: 0.0855	 Validation loss: 0.1711
[70/740] Training loss: 0.0700	 Validation loss: 0.1539
[75/740] Training loss: 0.0583	 Validation loss: 0.1394
[80/740] Training loss: 0.0491	 Validation loss: 0.1269
[85/740] Training loss: 0.0417	 Validation loss: 0.1160
[90/740] Training loss: 0.0359	 Validation loss: 0.1064
[95/740] Training loss: 0.0310	 Validation loss: 0.0980
[100/740] Training loss: 0.0270	 Validation loss: 0.0907
[105/740] Training loss: 0.0237	 Validation loss: 0.0843
[110/740] Training loss: 0.0209	 Validation loss: 0.0787
[115/740] Training loss: 0.0185	 Validation loss: 0.0738
[120/740] Training loss: 0.0164	 Validation loss: 0.0694
[125/740] Training loss: 0.0146	 Validation loss: 0.0656
[130/740] Training loss: 0.0131	 Validation loss: 0.0622
[135/740] Training loss: 0.0118	 Validation loss: 0.0592
[140/740] Training loss: 0.0106	 Validation loss: 0.0566
[145/740] Training loss: 0.0096	 Validation loss: 0.0543
[150/740] Training loss: 0.0087	 Validation loss: 0.0522
[155/740] Training loss: 0.0079	 Validation loss: 0.0504
[160/740] Training loss: 0.0072	 Validation loss: 0.0489
[165/740] Training loss: 0.0066	 Validation loss: 0.0474
[170/740] Training loss: 0.0061	 Validation loss: 0.0461
[175/740] Training loss: 0.0056	 Validation loss: 0.0450
[180/740] Training loss: 0.0052	 Validation loss: 0.0439
[185/740] Training loss: 0.0048	 Validation loss: 0.0429
[190/740] Training loss: 0.0045	 Validation loss: 0.0420
[195/740] Training loss: 0.0042	 Validation loss: 0.0411
[200/740] Training loss: 0.0039	 Validation loss: 0.0403
[205/740] Training loss: 0.0037	 Validation loss: 0.0395
[210/740] Training loss: 0.0035	 Validation loss: 0.0387
[215/740] Training loss: 0.0033	 Validation loss: 0.0380
[220/740] Training loss: 0.0031	 Validation loss: 0.0373
[225/740] Training loss: 0.0029	 Validation loss: 0.0366
[230/740] Training loss: 0.0028	 Validation loss: 0.0360
[235/740] Training loss: 0.0026	 Validation loss: 0.0354
[240/740] Training loss: 0.0025	 Validation loss: 0.0348
[245/740] Training loss: 0.0024	 Validation loss: 0.0342
[250/740] Training loss: 0.0023	 Validation loss: 0.0337
[255/740] Training loss: 0.0021	 Validation loss: 0.0331
[260/740] Training loss: 0.0020	 Validation loss: 0.0327
[265/740] Training loss: 0.0020	 Validation loss: 0.0322
[270/740] Training loss: 0.0019	 Validation loss: 0.0317
[275/740] Training loss: 0.0018	 Validation loss: 0.0313
[280/740] Training loss: 0.0017	 Validation loss: 0.0309
[285/740] Training loss: 0.0016	 Validation loss: 0.0305
[290/740] Training loss: 0.0016	 Validation loss: 0.0302
[295/740] Training loss: 0.0015	 Validation loss: 0.0298
[300/740] Training loss: 0.0015	 Validation loss: 0.0295
[305/740] Training loss: 0.0014	 Validation loss: 0.0292
[310/740] Training loss: 0.0013	 Validation loss: 0.0289
[315/740] Training loss: 0.0013	 Validation loss: 0.0286
[320/740] Training loss: 0.0012	 Validation loss: 0.0283
[325/740] Training loss: 0.0012	 Validation loss: 0.0281
[330/740] Training loss: 0.0012	 Validation loss: 0.0278
[335/740] Training loss: 0.0011	 Validation loss: 0.0276
[340/740] Training loss: 0.0011	 Validation loss: 0.0274
[345/740] Training loss: 0.0010	 Validation loss: 0.0271
[350/740] Training loss: 0.0010	 Validation loss: 0.0269
[355/740] Training loss: 0.0010	 Validation loss: 0.0267
[360/740] Training loss: 0.0010	 Validation loss: 0.0265
[365/740] Training loss: 0.0009	 Validation loss: 0.0264
[370/740] Training loss: 0.0009	 Validation loss: 0.0262
[375/740] Training loss: 0.0009	 Validation loss: 0.0261
[380/740] Training loss: 0.0009	 Validation loss: 0.0259
[385/740] Training loss: 0.0009	 Validation loss: 0.0258
[390/740] Training loss: 0.0008	 Validation loss: 0.0256
[395/740] Training loss: 0.0008	 Validation loss: 0.0254
[400/740] Training loss: 0.0008	 Validation loss: 0.0252
[405/740] Training loss: 0.0008	 Validation loss: 0.0249
[410/740] Training loss: 0.0008	 Validation loss: 0.0247
[415/740] Training loss: 0.0008	 Validation loss: 0.0244
[420/740] Training loss: 0.0007	 Validation loss: 0.0242
[425/740] Training loss: 0.0007	 Validation loss: 0.0240
[430/740] Training loss: 0.0007	 Validation loss: 0.0239
[435/740] Training loss: 0.0008	 Validation loss: 0.0239
[440/740] Training loss: 0.0008	 Validation loss: 0.0237
[445/740] Training loss: 0.0007	 Validation loss: 0.0235
[450/740] Training loss: 0.0007	 Validation loss: 0.0239
[455/740] Training loss: 0.0007	 Validation loss: 0.0235
[460/740] Training loss: 0.0007	 Validation loss: 0.0232
[465/740] Training loss: 0.0007	 Validation loss: 0.0230
[470/740] Training loss: 0.0007	 Validation loss: 0.0222
[475/740] Training loss: 0.0007	 Validation loss: 0.0212
[480/740] Training loss: 0.0006	 Validation loss: 0.0209
[485/740] Training loss: 0.0009	 Validation loss: 0.0202
[490/740] Training loss: 0.0009	 Validation loss: 0.0197
[495/740] Training loss: 0.0010	 Validation loss: 0.0204
[500/740] Training loss: 0.0009	 Validation loss: 0.0217
[505/740] Training loss: 0.0010	 Validation loss: 0.0226
[510/740] Training loss: 0.0007	 Validation loss: 0.0226
[515/740] Training loss: 0.0005	 Validation loss: 0.0224
[520/740] Training loss: 0.0005	 Validation loss: 0.0223
[525/740] Training loss: 0.0005	 Validation loss: 0.0224
[530/740] Training loss: 0.0005	 Validation loss: 0.0225
[535/740] Training loss: 0.0006	 Validation loss: 0.0225
[540/740] Training loss: 0.0006	 Validation loss: 0.0224
[545/740] Training loss: 0.0006	 Validation loss: 0.0220
[550/740] Training loss: 0.0006	 Validation loss: 0.0214
[555/740] Training loss: 0.0006	 Validation loss: 0.0206
[560/740] Training loss: 0.0005	 Validation loss: 0.0198
[565/740] Training loss: 0.0005	 Validation loss: 0.0190
[570/740] Training loss: 0.0006	 Validation loss: 0.0181
[575/740] Training loss: 0.0007	 Validation loss: 0.0176
[580/740] Training loss: 0.0013	 Validation loss: 0.0182
[585/740] Training loss: 0.0009	 Validation loss: 0.0204
[590/740] Training loss: 0.0010	 Validation loss: 0.0215
[595/740] Training loss: 0.0010	 Validation loss: 0.0206
[600/740] Training loss: 0.0007	 Validation loss: 0.0205
[605/740] Training loss: 0.0005	 Validation loss: 0.0210
[610/740] Training loss: 0.0004	 Validation loss: 0.0213
[615/740] Training loss: 0.0005	 Validation loss: 0.0215
[620/740] Training loss: 0.0006	 Validation loss: 0.0216
[625/740] Training loss: 0.0006	 Validation loss: 0.0213
[630/740] Training loss: 0.0006	 Validation loss: 0.0206
[635/740] Training loss: 0.0005	 Validation loss: 0.0197
[640/740] Training loss: 0.0005	 Validation loss: 0.0188
[645/740] Training loss: 0.0005	 Validation loss: 0.0181
[650/740] Training loss: 0.0005	 Validation loss: 0.0176
[655/740] Training loss: 0.0005	 Validation loss: 0.0173
[660/740] Training loss: 0.0007	 Validation loss: 0.0171
[665/740] Training loss: 0.0007	 Validation loss: 0.0180
[670/740] Training loss: 0.0007	 Validation loss: 0.0200
[675/740] Training loss: 0.0008	 Validation loss: 0.0219
[680/740] Training loss: 0.0011	 Validation loss: 0.0223
[685/740] Training loss: 0.0007	 Validation loss: 0.0206
[690/740] Training loss: 0.0004	 Validation loss: 0.0200
[695/740] Training loss: 0.0005	 Validation loss: 0.0205
[700/740] Training loss: 0.0005	 Validation loss: 0.0206
[705/740] Training loss: 0.0006	 Validation loss: 0.0209
[710/740] Training loss: 0.0007	 Validation loss: 0.0207
[715/740] Training loss: 0.0008	 Validation loss: 0.0200
[720/740] Training loss: 0.0007	 Validation loss: 0.0185
[725/740] Training loss: 0.0006	 Validation loss: 0.0175
[730/740] Training loss: 0.0008	 Validation loss: 0.0178
[735/740] Training loss: 0.0007	 Validation loss: 0.0192
[740/740] Training loss: 0.0006	 Validation loss: 0.0203
Bus error (core dumped)
