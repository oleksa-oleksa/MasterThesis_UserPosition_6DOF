INFO:root:LSTM Pure PyTorch: hidden_dim: 24, n_epochs: 740, batch_size: 4096.
INFO:root:Trace path: data/flipped/1556.csv
INFO:root:Prediction window = 100.0 ms
INFO:root:MAE position = 0.07513869222005208
INFO:root:MAE rotation = 2.72867487069815
INFO:root:RMSE position = 0.13971637
INFO:root:RMSE rotation = 3.7430154054432423
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/opt/UserPrediction6DOF/__main__.py", line 45, in <module>
    APPLICATION.run()
  File "/opt/UserPrediction6DOF/application.py", line 91, in run
    self.run_lstm()
  File "/opt/UserPrediction6DOF/application.py", line 138, in run_lstm
    runner.run()
  File "/opt/UserPrediction6DOF/runners.py", line 394, in run
    'euc_dists_lstm_{}_{}ms.npy'.format(basename, int(w * 1e3))), euc_dists)
  File "<__array_function__ internals>", line 6, in save
  File "/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py", line 525, in save
    file_ctx = open(file, "wb")
OSError: [Errno 30] Read-only file system: './results/tabular/distances/euc_dists_lstm_1556_100ms.npy'
-------------------------------------------------------------------------
-------------------------------------------------------------------------
X_train (71999, 11), X_val (24000, 11), X_test(24000, 11), y_train (71999, 7), y_val (24000, 7), y_test (24000, 7)
[1/740] Training loss: 4.9979	 Validation loss: 2.7669
[2/740] Training loss: 4.8295	 Validation loss: 2.6437
[3/740] Training loss: 4.6558	 Validation loss: 2.5157
[4/740] Training loss: 4.4708	 Validation loss: 2.3811
[5/740] Training loss: 4.2734	 Validation loss: 2.2405
[10/740] Training loss: 3.2127	 Validation loss: 1.5483
[15/740] Training loss: 2.2782	 Validation loss: 1.0172
[20/740] Training loss: 1.5478	 Validation loss: 0.6564
[25/740] Training loss: 1.0447	 Validation loss: 0.4507
[30/740] Training loss: 0.7372	 Validation loss: 0.3601
[35/740] Training loss: 0.5574	 Validation loss: 0.3286
[40/740] Training loss: 0.4453	 Validation loss: 0.3114
[45/740] Training loss: 0.3622	 Validation loss: 0.2914
[50/740] Training loss: 0.2954	 Validation loss: 0.2712
[55/740] Training loss: 0.2409	 Validation loss: 0.2465
[60/740] Training loss: 0.1973	 Validation loss: 0.2223
[65/740] Training loss: 0.1628	 Validation loss: 0.2019
[70/740] Training loss: 0.1354	 Validation loss: 0.1850
[75/740] Training loss: 0.1136	 Validation loss: 0.1709
[80/740] Training loss: 0.0962	 Validation loss: 0.1589
[85/740] Training loss: 0.0823	 Validation loss: 0.1485
[90/740] Training loss: 0.0710	 Validation loss: 0.1394
[95/740] Training loss: 0.0618	 Validation loss: 0.1313
[100/740] Training loss: 0.0542	 Validation loss: 0.1241
[105/740] Training loss: 0.0479	 Validation loss: 0.1176
[110/740] Training loss: 0.0426	 Validation loss: 0.1117
[115/740] Training loss: 0.0382	 Validation loss: 0.1064
[120/740] Training loss: 0.0343	 Validation loss: 0.1014
[125/740] Training loss: 0.0310	 Validation loss: 0.0967
[130/740] Training loss: 0.0282	 Validation loss: 0.0922
[135/740] Training loss: 0.0257	 Validation loss: 0.0881
[140/740] Training loss: 0.0235	 Validation loss: 0.0841
[145/740] Training loss: 0.0215	 Validation loss: 0.0803
[150/740] Training loss: 0.0198	 Validation loss: 0.0768
[155/740] Training loss: 0.0182	 Validation loss: 0.0735
[160/740] Training loss: 0.0168	 Validation loss: 0.0703
[165/740] Training loss: 0.0156	 Validation loss: 0.0673
[170/740] Training loss: 0.0145	 Validation loss: 0.0644
[175/740] Training loss: 0.0134	 Validation loss: 0.0617
[180/740] Training loss: 0.0125	 Validation loss: 0.0590
[185/740] Training loss: 0.0117	 Validation loss: 0.0565
[190/740] Training loss: 0.0109	 Validation loss: 0.0541
[195/740] Training loss: 0.0102	 Validation loss: 0.0519
[200/740] Training loss: 0.0095	 Validation loss: 0.0497
[205/740] Training loss: 0.0089	 Validation loss: 0.0477
[210/740] Training loss: 0.0083	 Validation loss: 0.0458
[215/740] Training loss: 0.0078	 Validation loss: 0.0440
[220/740] Training loss: 0.0073	 Validation loss: 0.0423
[225/740] Training loss: 0.0069	 Validation loss: 0.0408
[230/740] Training loss: 0.0065	 Validation loss: 0.0393
[235/740] Training loss: 0.0061	 Validation loss: 0.0380
[240/740] Training loss: 0.0057	 Validation loss: 0.0368
[245/740] Training loss: 0.0054	 Validation loss: 0.0358
[250/740] Training loss: 0.0051	 Validation loss: 0.0348
[255/740] Training loss: 0.0048	 Validation loss: 0.0339
[260/740] Training loss: 0.0046	 Validation loss: 0.0331
[265/740] Training loss: 0.0043	 Validation loss: 0.0324
[270/740] Training loss: 0.0041	 Validation loss: 0.0317
[275/740] Training loss: 0.0039	 Validation loss: 0.0311
[280/740] Training loss: 0.0037	 Validation loss: 0.0306
[285/740] Training loss: 0.0035	 Validation loss: 0.0301
[290/740] Training loss: 0.0034	 Validation loss: 0.0296
[295/740] Training loss: 0.0032	 Validation loss: 0.0292
[300/740] Training loss: 0.0031	 Validation loss: 0.0289
[305/740] Training loss: 0.0030	 Validation loss: 0.0285
[310/740] Training loss: 0.0028	 Validation loss: 0.0282
[315/740] Training loss: 0.0027	 Validation loss: 0.0279
[320/740] Training loss: 0.0026	 Validation loss: 0.0276
[325/740] Training loss: 0.0025	 Validation loss: 0.0273
[330/740] Training loss: 0.0025	 Validation loss: 0.0271
[335/740] Training loss: 0.0024	 Validation loss: 0.0268
[340/740] Training loss: 0.0023	 Validation loss: 0.0265
[345/740] Training loss: 0.0022	 Validation loss: 0.0263
[350/740] Training loss: 0.0021	 Validation loss: 0.0260
[355/740] Training loss: 0.0021	 Validation loss: 0.0258
[360/740] Training loss: 0.0020	 Validation loss: 0.0256
[365/740] Training loss: 0.0020	 Validation loss: 0.0253
[370/740] Training loss: 0.0019	 Validation loss: 0.0251
[375/740] Training loss: 0.0019	 Validation loss: 0.0248
[380/740] Training loss: 0.0018	 Validation loss: 0.0246
[385/740] Training loss: 0.0018	 Validation loss: 0.0243
[390/740] Training loss: 0.0017	 Validation loss: 0.0241
[395/740] Training loss: 0.0017	 Validation loss: 0.0238
[400/740] Training loss: 0.0016	 Validation loss: 0.0236
[405/740] Training loss: 0.0016	 Validation loss: 0.0233
[410/740] Training loss: 0.0015	 Validation loss: 0.0231
[415/740] Training loss: 0.0015	 Validation loss: 0.0229
[420/740] Training loss: 0.0015	 Validation loss: 0.0226
[425/740] Training loss: 0.0014	 Validation loss: 0.0224
[430/740] Training loss: 0.0014	 Validation loss: 0.0222
[435/740] Training loss: 0.0014	 Validation loss: 0.0220
[440/740] Training loss: 0.0013	 Validation loss: 0.0218
[445/740] Training loss: 0.0013	 Validation loss: 0.0216
[450/740] Training loss: 0.0013	 Validation loss: 0.0214
[455/740] Training loss: 0.0013	 Validation loss: 0.0212
[460/740] Training loss: 0.0014	 Validation loss: 0.0209
[465/740] Training loss: 0.0014	 Validation loss: 0.0211
[470/740] Training loss: 0.0012	 Validation loss: 0.0209
[475/740] Training loss: 0.0012	 Validation loss: 0.0210
[480/740] Training loss: 0.0012	 Validation loss: 0.0209
[485/740] Training loss: 0.0012	 Validation loss: 0.0203
[490/740] Training loss: 0.0011	 Validation loss: 0.0198
[495/740] Training loss: 0.0011	 Validation loss: 0.0199
[500/740] Training loss: 0.0013	 Validation loss: 0.0203
[505/740] Training loss: 0.0018	 Validation loss: 0.0202
[510/740] Training loss: 0.0019	 Validation loss: 0.0200
[515/740] Training loss: 0.0013	 Validation loss: 0.0183
[520/740] Training loss: 0.0012	 Validation loss: 0.0185
[525/740] Training loss: 0.0010	 Validation loss: 0.0186
[530/740] Training loss: 0.0009	 Validation loss: 0.0186
[535/740] Training loss: 0.0009	 Validation loss: 0.0185
[540/740] Training loss: 0.0009	 Validation loss: 0.0185
[545/740] Training loss: 0.0009	 Validation loss: 0.0184
[550/740] Training loss: 0.0009	 Validation loss: 0.0184
[555/740] Training loss: 0.0009	 Validation loss: 0.0184
[560/740] Training loss: 0.0009	 Validation loss: 0.0185
[565/740] Training loss: 0.0011	 Validation loss: 0.0185
[570/740] Training loss: 0.0011	 Validation loss: 0.0184
[575/740] Training loss: 0.0010	 Validation loss: 0.0186
[580/740] Training loss: 0.0010	 Validation loss: 0.0184
[585/740] Training loss: 0.0009	 Validation loss: 0.0182
[590/740] Training loss: 0.0009	 Validation loss: 0.0179
[595/740] Training loss: 0.0008	 Validation loss: 0.0177
[600/740] Training loss: 0.0008	 Validation loss: 0.0174
[605/740] Training loss: 0.0008	 Validation loss: 0.0173
[610/740] Training loss: 0.0008	 Validation loss: 0.0172
[615/740] Training loss: 0.0008	 Validation loss: 0.0173
[620/740] Training loss: 0.0009	 Validation loss: 0.0177
[625/740] Training loss: 0.0010	 Validation loss: 0.0179
[630/740] Training loss: 0.0008	 Validation loss: 0.0171
[635/740] Training loss: 0.0010	 Validation loss: 0.0194
[640/740] Training loss: 0.0009	 Validation loss: 0.0176
[645/740] Training loss: 0.0009	 Validation loss: 0.0179
[650/740] Training loss: 0.0009	 Validation loss: 0.0183
[655/740] Training loss: 0.0009	 Validation loss: 0.0178
[660/740] Training loss: 0.0009	 Validation loss: 0.0171
[665/740] Training loss: 0.0009	 Validation loss: 0.0163
[670/740] Training loss: 0.0010	 Validation loss: 0.0157
[675/740] Training loss: 0.0023	 Validation loss: 0.0168
[680/740] Training loss: 0.0017	 Validation loss: 0.0174
[685/740] Training loss: 0.0007	 Validation loss: 0.0177
[690/740] Training loss: 0.0006	 Validation loss: 0.0175
[695/740] Training loss: 0.0006	 Validation loss: 0.0175
[700/740] Training loss: 0.0006	 Validation loss: 0.0175
[705/740] Training loss: 0.0006	 Validation loss: 0.0174
[710/740] Training loss: 0.0006	 Validation loss: 0.0174
[715/740] Training loss: 0.0006	 Validation loss: 0.0174
[720/740] Training loss: 0.0006	 Validation loss: 0.0174
[725/740] Training loss: 0.0006	 Validation loss: 0.0176
[730/740] Training loss: 0.0006	 Validation loss: 0.0178
[735/740] Training loss: 0.0007	 Validation loss: 0.0182
[740/740] Training loss: 0.0008	 Validation loss: 0.0185
