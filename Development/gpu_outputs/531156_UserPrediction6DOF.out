INFO:root:LSTM Pure PyTorch: hidden_dim: 36, n_epochs: 740, batch_size: 8192.
INFO:root:Trace path: data/flipped/1556.csv
INFO:root:Prediction window = 100.0 ms
INFO:root:MAE position = 0.08035463460286459
INFO:root:MAE rotation = 2.5815868361505734
INFO:root:RMSE position = 0.15950781
INFO:root:RMSE rotation = 3.4578907741027445
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/opt/UserPrediction6DOF/__main__.py", line 45, in <module>
    APPLICATION.run()
  File "/opt/UserPrediction6DOF/application.py", line 91, in run
    self.run_lstm()
  File "/opt/UserPrediction6DOF/application.py", line 138, in run_lstm
    runner.run()
  File "/opt/UserPrediction6DOF/runners.py", line 394, in run
    'euc_dists_lstm_{}_{}ms.npy'.format(basename, int(w * 1e3))), euc_dists)
  File "<__array_function__ internals>", line 6, in save
  File "/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py", line 525, in save
    file_ctx = open(file, "wb")
OSError: [Errno 30] Read-only file system: './results/tabular/distances/euc_dists_lstm_1556_100ms.npy'
-------------------------------------------------------------------------
-------------------------------------------------------------------------
X_train (71999, 11), X_val (24000, 11), X_test(24000, 11), y_train (71999, 7), y_val (24000, 7), y_test (24000, 7)
[1/740] Training loss: 4.7637	 Validation loss: 3.1881
[2/740] Training loss: 4.6669	 Validation loss: 3.1215
[3/740] Training loss: 4.5724	 Validation loss: 3.0543
[4/740] Training loss: 4.4772	 Validation loss: 2.9855
[5/740] Training loss: 4.3801	 Validation loss: 2.9142
[10/740] Training loss: 3.8344	 Validation loss: 2.5053
[15/740] Training loss: 3.1768	 Validation loss: 2.0265
[20/740] Training loss: 2.4663	 Validation loss: 1.5419
[25/740] Training loss: 1.8046	 Validation loss: 1.1184
[30/740] Training loss: 1.2698	 Validation loss: 0.7959
[35/740] Training loss: 0.8884	 Validation loss: 0.5848
[40/740] Training loss: 0.6407	 Validation loss: 0.4657
[45/740] Training loss: 0.4872	 Validation loss: 0.4069
[50/740] Training loss: 0.3913	 Validation loss: 0.3787
[55/740] Training loss: 0.3271	 Validation loss: 0.3612
[60/740] Training loss: 0.2792	 Validation loss: 0.3455
[65/740] Training loss: 0.2398	 Validation loss: 0.3292
[70/740] Training loss: 0.2061	 Validation loss: 0.3125
[75/740] Training loss: 0.1771	 Validation loss: 0.2958
[80/740] Training loss: 0.1524	 Validation loss: 0.2790
[85/740] Training loss: 0.1313	 Validation loss: 0.2623
[90/740] Training loss: 0.1133	 Validation loss: 0.2460
[95/740] Training loss: 0.0980	 Validation loss: 0.2304
[100/740] Training loss: 0.0850	 Validation loss: 0.2158
[105/740] Training loss: 0.0739	 Validation loss: 0.2023
[110/740] Training loss: 0.0645	 Validation loss: 0.1898
[115/740] Training loss: 0.0565	 Validation loss: 0.1784
[120/740] Training loss: 0.0498	 Validation loss: 0.1679
[125/740] Training loss: 0.0440	 Validation loss: 0.1583
[130/740] Training loss: 0.0391	 Validation loss: 0.1494
[135/740] Training loss: 0.0348	 Validation loss: 0.1413
[140/740] Training loss: 0.0312	 Validation loss: 0.1339
[145/740] Training loss: 0.0281	 Validation loss: 0.1271
[150/740] Training loss: 0.0253	 Validation loss: 0.1209
[155/740] Training loss: 0.0230	 Validation loss: 0.1152
[160/740] Training loss: 0.0209	 Validation loss: 0.1100
[165/740] Training loss: 0.0191	 Validation loss: 0.1053
[170/740] Training loss: 0.0175	 Validation loss: 0.1010
[175/740] Training loss: 0.0161	 Validation loss: 0.0971
[180/740] Training loss: 0.0149	 Validation loss: 0.0935
[185/740] Training loss: 0.0138	 Validation loss: 0.0902
[190/740] Training loss: 0.0128	 Validation loss: 0.0872
[195/740] Training loss: 0.0119	 Validation loss: 0.0844
[200/740] Training loss: 0.0111	 Validation loss: 0.0819
[205/740] Training loss: 0.0104	 Validation loss: 0.0795
[210/740] Training loss: 0.0097	 Validation loss: 0.0773
[215/740] Training loss: 0.0091	 Validation loss: 0.0753
[220/740] Training loss: 0.0086	 Validation loss: 0.0735
[225/740] Training loss: 0.0081	 Validation loss: 0.0717
[230/740] Training loss: 0.0077	 Validation loss: 0.0701
[235/740] Training loss: 0.0072	 Validation loss: 0.0686
[240/740] Training loss: 0.0069	 Validation loss: 0.0672
[245/740] Training loss: 0.0065	 Validation loss: 0.0659
[250/740] Training loss: 0.0062	 Validation loss: 0.0647
[255/740] Training loss: 0.0059	 Validation loss: 0.0635
[260/740] Training loss: 0.0056	 Validation loss: 0.0624
[265/740] Training loss: 0.0054	 Validation loss: 0.0614
[270/740] Training loss: 0.0051	 Validation loss: 0.0604
[275/740] Training loss: 0.0049	 Validation loss: 0.0594
[280/740] Training loss: 0.0047	 Validation loss: 0.0585
[285/740] Training loss: 0.0045	 Validation loss: 0.0577
[290/740] Training loss: 0.0043	 Validation loss: 0.0569
[295/740] Training loss: 0.0041	 Validation loss: 0.0561
[300/740] Training loss: 0.0040	 Validation loss: 0.0554
[305/740] Training loss: 0.0038	 Validation loss: 0.0546
[310/740] Training loss: 0.0037	 Validation loss: 0.0540
[315/740] Training loss: 0.0035	 Validation loss: 0.0533
[320/740] Training loss: 0.0034	 Validation loss: 0.0526
[325/740] Training loss: 0.0033	 Validation loss: 0.0520
[330/740] Training loss: 0.0031	 Validation loss: 0.0514
[335/740] Training loss: 0.0030	 Validation loss: 0.0508
[340/740] Training loss: 0.0029	 Validation loss: 0.0502
[345/740] Training loss: 0.0028	 Validation loss: 0.0497
[350/740] Training loss: 0.0027	 Validation loss: 0.0492
[355/740] Training loss: 0.0026	 Validation loss: 0.0486
[360/740] Training loss: 0.0026	 Validation loss: 0.0481
[365/740] Training loss: 0.0025	 Validation loss: 0.0476
[370/740] Training loss: 0.0024	 Validation loss: 0.0472
[375/740] Training loss: 0.0023	 Validation loss: 0.0467
[380/740] Training loss: 0.0023	 Validation loss: 0.0463
[385/740] Training loss: 0.0022	 Validation loss: 0.0458
[390/740] Training loss: 0.0021	 Validation loss: 0.0454
[395/740] Training loss: 0.0021	 Validation loss: 0.0450
[400/740] Training loss: 0.0020	 Validation loss: 0.0446
[405/740] Training loss: 0.0019	 Validation loss: 0.0443
[410/740] Training loss: 0.0019	 Validation loss: 0.0439
[415/740] Training loss: 0.0018	 Validation loss: 0.0436
[420/740] Training loss: 0.0018	 Validation loss: 0.0432
[425/740] Training loss: 0.0017	 Validation loss: 0.0429
[430/740] Training loss: 0.0017	 Validation loss: 0.0426
[435/740] Training loss: 0.0016	 Validation loss: 0.0423
[440/740] Training loss: 0.0016	 Validation loss: 0.0420
[445/740] Training loss: 0.0015	 Validation loss: 0.0417
[450/740] Training loss: 0.0015	 Validation loss: 0.0415
[455/740] Training loss: 0.0015	 Validation loss: 0.0412
[460/740] Training loss: 0.0014	 Validation loss: 0.0410
[465/740] Training loss: 0.0014	 Validation loss: 0.0407
[470/740] Training loss: 0.0014	 Validation loss: 0.0405
[475/740] Training loss: 0.0013	 Validation loss: 0.0403
[480/740] Training loss: 0.0013	 Validation loss: 0.0401
[485/740] Training loss: 0.0013	 Validation loss: 0.0399
[490/740] Training loss: 0.0012	 Validation loss: 0.0397
[495/740] Training loss: 0.0012	 Validation loss: 0.0396
[500/740] Training loss: 0.0012	 Validation loss: 0.0394
[505/740] Training loss: 0.0011	 Validation loss: 0.0392
[510/740] Training loss: 0.0011	 Validation loss: 0.0391
[515/740] Training loss: 0.0011	 Validation loss: 0.0389
[520/740] Training loss: 0.0011	 Validation loss: 0.0388
[525/740] Training loss: 0.0010	 Validation loss: 0.0386
[530/740] Training loss: 0.0010	 Validation loss: 0.0385
[535/740] Training loss: 0.0010	 Validation loss: 0.0384
[540/740] Training loss: 0.0010	 Validation loss: 0.0383
[545/740] Training loss: 0.0009	 Validation loss: 0.0381
[550/740] Training loss: 0.0009	 Validation loss: 0.0380
[555/740] Training loss: 0.0009	 Validation loss: 0.0379
[560/740] Training loss: 0.0009	 Validation loss: 0.0378
[565/740] Training loss: 0.0009	 Validation loss: 0.0377
[570/740] Training loss: 0.0009	 Validation loss: 0.0376
[575/740] Training loss: 0.0008	 Validation loss: 0.0375
[580/740] Training loss: 0.0008	 Validation loss: 0.0375
[585/740] Training loss: 0.0008	 Validation loss: 0.0374
[590/740] Training loss: 0.0008	 Validation loss: 0.0373
[595/740] Training loss: 0.0008	 Validation loss: 0.0372
[600/740] Training loss: 0.0008	 Validation loss: 0.0371
[605/740] Training loss: 0.0008	 Validation loss: 0.0370
[610/740] Training loss: 0.0007	 Validation loss: 0.0370
[615/740] Training loss: 0.0007	 Validation loss: 0.0369
[620/740] Training loss: 0.0007	 Validation loss: 0.0368
[625/740] Training loss: 0.0007	 Validation loss: 0.0368
[630/740] Training loss: 0.0007	 Validation loss: 0.0367
[635/740] Training loss: 0.0007	 Validation loss: 0.0366
[640/740] Training loss: 0.0007	 Validation loss: 0.0366
[645/740] Training loss: 0.0007	 Validation loss: 0.0365
[650/740] Training loss: 0.0007	 Validation loss: 0.0365
[655/740] Training loss: 0.0006	 Validation loss: 0.0364
[660/740] Training loss: 0.0006	 Validation loss: 0.0363
[665/740] Training loss: 0.0006	 Validation loss: 0.0363
[670/740] Training loss: 0.0006	 Validation loss: 0.0362
[675/740] Training loss: 0.0006	 Validation loss: 0.0362
[680/740] Training loss: 0.0006	 Validation loss: 0.0361
[685/740] Training loss: 0.0006	 Validation loss: 0.0360
[690/740] Training loss: 0.0006	 Validation loss: 0.0360
[695/740] Training loss: 0.0006	 Validation loss: 0.0359
[700/740] Training loss: 0.0006	 Validation loss: 0.0359
[705/740] Training loss: 0.0006	 Validation loss: 0.0358
[710/740] Training loss: 0.0006	 Validation loss: 0.0358
[715/740] Training loss: 0.0005	 Validation loss: 0.0357
[720/740] Training loss: 0.0005	 Validation loss: 0.0356
[725/740] Training loss: 0.0005	 Validation loss: 0.0356
[730/740] Training loss: 0.0005	 Validation loss: 0.0355
[735/740] Training loss: 0.0005	 Validation loss: 0.0354
[740/740] Training loss: 0.0005	 Validation loss: 0.0354
