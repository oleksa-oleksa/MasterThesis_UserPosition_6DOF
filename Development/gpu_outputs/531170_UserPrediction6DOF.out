INFO:root:LSTM Pure PyTorch: hidden_dim: 24, n_epochs: 740, batch_size: 4096.
INFO:root:Trace path: data/flipped/1556.csv
INFO:root:Prediction window = 100.0 ms
INFO:root:MAE position = 0.11522745768229167
INFO:root:MAE rotation = 2.9463533963016078
INFO:root:RMSE position = 0.15506545
INFO:root:RMSE rotation = 3.8615331798419685
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/opt/UserPrediction6DOF/__main__.py", line 45, in <module>
    APPLICATION.run()
  File "/opt/UserPrediction6DOF/application.py", line 91, in run
    self.run_lstm()
  File "/opt/UserPrediction6DOF/application.py", line 138, in run_lstm
    runner.run()
  File "/opt/UserPrediction6DOF/runners.py", line 394, in run
    'euc_dists_lstm_{}_{}ms.npy'.format(basename, int(w * 1e3))), euc_dists)
  File "<__array_function__ internals>", line 6, in save
  File "/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py", line 525, in save
    file_ctx = open(file, "wb")
OSError: [Errno 30] Read-only file system: './results/tabular/distances/euc_dists_lstm_1556_100ms.npy'
-------------------------------------------------------------------------
-------------------------------------------------------------------------
X_train (71999, 11), X_val (24000, 11), X_test(24000, 11), y_train (71999, 7), y_val (24000, 7), y_test (24000, 7)
[1/740] Training loss: 5.1426	 Validation loss: 2.9790
[2/740] Training loss: 5.0094	 Validation loss: 2.8879
[3/740] Training loss: 4.8694	 Validation loss: 2.7908
[4/740] Training loss: 4.7136	 Validation loss: 2.6827
[5/740] Training loss: 4.5374	 Validation loss: 2.5611
[10/740] Training loss: 3.4216	 Validation loss: 1.8241
[15/740] Training loss: 2.3378	 Validation loss: 1.1733
[20/740] Training loss: 1.5362	 Validation loss: 0.7351
[25/740] Training loss: 1.0180	 Validation loss: 0.4852
[30/740] Training loss: 0.7135	 Validation loss: 0.3708
[35/740] Training loss: 0.5372	 Validation loss: 0.3251
[40/740] Training loss: 0.4244	 Validation loss: 0.2960
[45/740] Training loss: 0.3396	 Validation loss: 0.2647
[50/740] Training loss: 0.2707	 Validation loss: 0.2366
[55/740] Training loss: 0.2161	 Validation loss: 0.2143
[60/740] Training loss: 0.1741	 Validation loss: 0.1954
[65/740] Training loss: 0.1419	 Validation loss: 0.1779
[70/740] Training loss: 0.1170	 Validation loss: 0.1616
[75/740] Training loss: 0.0975	 Validation loss: 0.1470
[80/740] Training loss: 0.0822	 Validation loss: 0.1340
[85/740] Training loss: 0.0700	 Validation loss: 0.1227
[90/740] Training loss: 0.0602	 Validation loss: 0.1126
[95/740] Training loss: 0.0521	 Validation loss: 0.1038
[100/740] Training loss: 0.0455	 Validation loss: 0.0959
[105/740] Training loss: 0.0399	 Validation loss: 0.0889
[110/740] Training loss: 0.0353	 Validation loss: 0.0826
[115/740] Training loss: 0.0313	 Validation loss: 0.0770
[120/740] Training loss: 0.0279	 Validation loss: 0.0719
[125/740] Training loss: 0.0250	 Validation loss: 0.0673
[130/740] Training loss: 0.0225	 Validation loss: 0.0632
[135/740] Training loss: 0.0203	 Validation loss: 0.0595
[140/740] Training loss: 0.0183	 Validation loss: 0.0561
[145/740] Training loss: 0.0166	 Validation loss: 0.0531
[150/740] Training loss: 0.0151	 Validation loss: 0.0505
[155/740] Training loss: 0.0138	 Validation loss: 0.0481
[160/740] Training loss: 0.0126	 Validation loss: 0.0459
[165/740] Training loss: 0.0116	 Validation loss: 0.0440
[170/740] Training loss: 0.0107	 Validation loss: 0.0422
[175/740] Training loss: 0.0098	 Validation loss: 0.0406
[180/740] Training loss: 0.0091	 Validation loss: 0.0391
[185/740] Training loss: 0.0084	 Validation loss: 0.0378
[190/740] Training loss: 0.0078	 Validation loss: 0.0365
[195/740] Training loss: 0.0073	 Validation loss: 0.0353
[200/740] Training loss: 0.0068	 Validation loss: 0.0342
[205/740] Training loss: 0.0064	 Validation loss: 0.0332
[210/740] Training loss: 0.0060	 Validation loss: 0.0323
[215/740] Training loss: 0.0056	 Validation loss: 0.0314
[220/740] Training loss: 0.0052	 Validation loss: 0.0305
[225/740] Training loss: 0.0049	 Validation loss: 0.0297
[230/740] Training loss: 0.0046	 Validation loss: 0.0290
[235/740] Training loss: 0.0044	 Validation loss: 0.0282
[240/740] Training loss: 0.0041	 Validation loss: 0.0276
[245/740] Training loss: 0.0039	 Validation loss: 0.0269
[250/740] Training loss: 0.0037	 Validation loss: 0.0264
[255/740] Training loss: 0.0035	 Validation loss: 0.0258
[260/740] Training loss: 0.0033	 Validation loss: 0.0253
[265/740] Training loss: 0.0032	 Validation loss: 0.0248
[270/740] Training loss: 0.0030	 Validation loss: 0.0244
[275/740] Training loss: 0.0029	 Validation loss: 0.0239
[280/740] Training loss: 0.0028	 Validation loss: 0.0236
[285/740] Training loss: 0.0026	 Validation loss: 0.0232
[290/740] Training loss: 0.0025	 Validation loss: 0.0229
[295/740] Training loss: 0.0024	 Validation loss: 0.0226
[300/740] Training loss: 0.0023	 Validation loss: 0.0223
[305/740] Training loss: 0.0022	 Validation loss: 0.0220
[310/740] Training loss: 0.0021	 Validation loss: 0.0217
[315/740] Training loss: 0.0020	 Validation loss: 0.0215
[320/740] Training loss: 0.0020	 Validation loss: 0.0213
[325/740] Training loss: 0.0019	 Validation loss: 0.0211
[330/740] Training loss: 0.0018	 Validation loss: 0.0209
[335/740] Training loss: 0.0018	 Validation loss: 0.0207
[340/740] Training loss: 0.0017	 Validation loss: 0.0205
[345/740] Training loss: 0.0016	 Validation loss: 0.0203
[350/740] Training loss: 0.0016	 Validation loss: 0.0202
[355/740] Training loss: 0.0015	 Validation loss: 0.0200
[360/740] Training loss: 0.0015	 Validation loss: 0.0199
[365/740] Training loss: 0.0015	 Validation loss: 0.0198
[370/740] Training loss: 0.0014	 Validation loss: 0.0197
[375/740] Training loss: 0.0014	 Validation loss: 0.0195
[380/740] Training loss: 0.0013	 Validation loss: 0.0194
[385/740] Training loss: 0.0013	 Validation loss: 0.0193
[390/740] Training loss: 0.0013	 Validation loss: 0.0192
[395/740] Training loss: 0.0013	 Validation loss: 0.0191
[400/740] Training loss: 0.0012	 Validation loss: 0.0191
[405/740] Training loss: 0.0012	 Validation loss: 0.0190
[410/740] Training loss: 0.0012	 Validation loss: 0.0189
[415/740] Training loss: 0.0012	 Validation loss: 0.0188
[420/740] Training loss: 0.0011	 Validation loss: 0.0187
[425/740] Training loss: 0.0011	 Validation loss: 0.0186
[430/740] Training loss: 0.0011	 Validation loss: 0.0185
[435/740] Training loss: 0.0011	 Validation loss: 0.0184
[440/740] Training loss: 0.0011	 Validation loss: 0.0184
[445/740] Training loss: 0.0011	 Validation loss: 0.0183
[450/740] Training loss: 0.0010	 Validation loss: 0.0181
[455/740] Training loss: 0.0011	 Validation loss: 0.0180
[460/740] Training loss: 0.0010	 Validation loss: 0.0181
[465/740] Training loss: 0.0010	 Validation loss: 0.0179
[470/740] Training loss: 0.0010	 Validation loss: 0.0176
[475/740] Training loss: 0.0009	 Validation loss: 0.0176
[480/740] Training loss: 0.0009	 Validation loss: 0.0175
[485/740] Training loss: 0.0009	 Validation loss: 0.0174
[490/740] Training loss: 0.0009	 Validation loss: 0.0174
[495/740] Training loss: 0.0009	 Validation loss: 0.0177
[500/740] Training loss: 0.0009	 Validation loss: 0.0176
[505/740] Training loss: 0.0011	 Validation loss: 0.0176
[510/740] Training loss: 0.0013	 Validation loss: 0.0180
[515/740] Training loss: 0.0012	 Validation loss: 0.0171
[520/740] Training loss: 0.0010	 Validation loss: 0.0166
[525/740] Training loss: 0.0012	 Validation loss: 0.0174
[530/740] Training loss: 0.0009	 Validation loss: 0.0174
[535/740] Training loss: 0.0008	 Validation loss: 0.0172
[540/740] Training loss: 0.0007	 Validation loss: 0.0169
[545/740] Training loss: 0.0007	 Validation loss: 0.0167
[550/740] Training loss: 0.0007	 Validation loss: 0.0165
[555/740] Training loss: 0.0007	 Validation loss: 0.0164
[560/740] Training loss: 0.0007	 Validation loss: 0.0163
[565/740] Training loss: 0.0008	 Validation loss: 0.0164
[570/740] Training loss: 0.0008	 Validation loss: 0.0164
[575/740] Training loss: 0.0009	 Validation loss: 0.0161
[580/740] Training loss: 0.0008	 Validation loss: 0.0159
[585/740] Training loss: 0.0008	 Validation loss: 0.0159
[590/740] Training loss: 0.0008	 Validation loss: 0.0154
[595/740] Training loss: 0.0008	 Validation loss: 0.0154
[600/740] Training loss: 0.0010	 Validation loss: 0.0154
[605/740] Training loss: 0.0011	 Validation loss: 0.0160
[610/740] Training loss: 0.0008	 Validation loss: 0.0160
[615/740] Training loss: 0.0008	 Validation loss: 0.0159
[620/740] Training loss: 0.0009	 Validation loss: 0.0161
[625/740] Training loss: 0.0008	 Validation loss: 0.0160
[630/740] Training loss: 0.0007	 Validation loss: 0.0159
[635/740] Training loss: 0.0006	 Validation loss: 0.0158
[640/740] Training loss: 0.0006	 Validation loss: 0.0155
[645/740] Training loss: 0.0006	 Validation loss: 0.0153
[650/740] Training loss: 0.0006	 Validation loss: 0.0151
[655/740] Training loss: 0.0006	 Validation loss: 0.0150
[660/740] Training loss: 0.0007	 Validation loss: 0.0152
[665/740] Training loss: 0.0009	 Validation loss: 0.0157
[670/740] Training loss: 0.0009	 Validation loss: 0.0153
[675/740] Training loss: 0.0007	 Validation loss: 0.0150
[680/740] Training loss: 0.0008	 Validation loss: 0.0145
[685/740] Training loss: 0.0009	 Validation loss: 0.0148
[690/740] Training loss: 0.0007	 Validation loss: 0.0144
[695/740] Training loss: 0.0006	 Validation loss: 0.0138
[700/740] Training loss: 0.0007	 Validation loss: 0.0134
[705/740] Training loss: 0.0006	 Validation loss: 0.0136
[710/740] Training loss: 0.0006	 Validation loss: 0.0138
[715/740] Training loss: 0.0006	 Validation loss: 0.0141
[720/740] Training loss: 0.0005	 Validation loss: 0.0148
[725/740] Training loss: 0.0006	 Validation loss: 0.0153
[730/740] Training loss: 0.0006	 Validation loss: 0.0158
[735/740] Training loss: 0.0009	 Validation loss: 0.0166
[740/740] Training loss: 0.0020	 Validation loss: 0.0165
