INFO:root:LSTM Pure PyTorch: hidden_dim: 24, n_epochs: 740, batch_size: 4096.
INFO:root:Trace path: data/flipped/1556.csv
INFO:root:Prediction window = 100.0 ms
INFO:root:MAE position = 0.07500077311197917
INFO:root:MAE rotation = 2.4607220144563584
INFO:root:RMSE position = 0.14049248
INFO:root:RMSE rotation = 3.084216618768469
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/opt/UserPrediction6DOF/__main__.py", line 45, in <module>
    APPLICATION.run()
  File "/opt/UserPrediction6DOF/application.py", line 91, in run
    self.run_lstm()
  File "/opt/UserPrediction6DOF/application.py", line 138, in run_lstm
    runner.run()
  File "/opt/UserPrediction6DOF/runners.py", line 394, in run
    'euc_dists_lstm_{}_{}ms.npy'.format(basename, int(w * 1e3))), euc_dists)
  File "<__array_function__ internals>", line 6, in save
  File "/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py", line 525, in save
OSError: [Errno 30] Read-only file system: './results/tabular/distances/euc_dists_lstm_1556_100ms.npy'
-------------------------------------------------------------------------
-------------------------------------------------------------------------
X_train (71999, 11), X_val (24000, 11), X_test(24000, 11), y_train (71999, 7), y_val (24000, 7), y_test (24000, 7)
[1/740] Training loss: 5.2334	 Validation loss: 2.9529
[2/740] Training loss: 5.0901	 Validation loss: 2.8460
[3/740] Training loss: 4.9494	 Validation loss: 2.7366
[4/740] Training loss: 4.8013	 Validation loss: 2.6194
[5/740] Training loss: 4.6383	 Validation loss: 2.4918
[10/740] Training loss: 3.5889	 Validation loss: 1.7494
[15/740] Training loss: 2.4637	 Validation loss: 1.0797
[20/740] Training loss: 1.5713	 Validation loss: 0.6308
[25/740] Training loss: 1.0057	 Validation loss: 0.4018
[30/740] Training loss: 0.6902	 Validation loss: 0.3178
[35/740] Training loss: 0.5186	 Validation loss: 0.2984
[40/740] Training loss: 0.4143	 Validation loss: 0.2887
[45/740] Training loss: 0.3363	 Validation loss: 0.2677
[50/740] Training loss: 0.2702	 Validation loss: 0.2395
[55/740] Training loss: 0.2162	 Validation loss: 0.2195
[60/740] Training loss: 0.1752	 Validation loss: 0.2058
[65/740] Training loss: 0.1436	 Validation loss: 0.1913
[70/740] Training loss: 0.1187	 Validation loss: 0.1760
[75/740] Training loss: 0.0989	 Validation loss: 0.1612
[80/740] Training loss: 0.0831	 Validation loss: 0.1474
[85/740] Training loss: 0.0704	 Validation loss: 0.1351
[90/740] Training loss: 0.0603	 Validation loss: 0.1242
[95/740] Training loss: 0.0520	 Validation loss: 0.1146
[100/740] Training loss: 0.0452	 Validation loss: 0.1061
[105/740] Training loss: 0.0397	 Validation loss: 0.0987
[110/740] Training loss: 0.0350	 Validation loss: 0.0921
[115/740] Training loss: 0.0311	 Validation loss: 0.0862
[120/740] Training loss: 0.0278	 Validation loss: 0.0809
[125/740] Training loss: 0.0250	 Validation loss: 0.0762
[130/740] Training loss: 0.0226	 Validation loss: 0.0720
[135/740] Training loss: 0.0205	 Validation loss: 0.0682
[140/740] Training loss: 0.0186	 Validation loss: 0.0648
[145/740] Training loss: 0.0170	 Validation loss: 0.0616
[150/740] Training loss: 0.0155	 Validation loss: 0.0588
[155/740] Training loss: 0.0142	 Validation loss: 0.0563
[160/740] Training loss: 0.0130	 Validation loss: 0.0540
[165/740] Training loss: 0.0120	 Validation loss: 0.0519
[170/740] Training loss: 0.0110	 Validation loss: 0.0500
[175/740] Training loss: 0.0101	 Validation loss: 0.0483
[180/740] Training loss: 0.0094	 Validation loss: 0.0467
[185/740] Training loss: 0.0087	 Validation loss: 0.0453
[190/740] Training loss: 0.0080	 Validation loss: 0.0440
[195/740] Training loss: 0.0075	 Validation loss: 0.0428
[200/740] Training loss: 0.0069	 Validation loss: 0.0417
[205/740] Training loss: 0.0065	 Validation loss: 0.0406
[210/740] Training loss: 0.0061	 Validation loss: 0.0397
[215/740] Training loss: 0.0057	 Validation loss: 0.0388
[220/740] Training loss: 0.0053	 Validation loss: 0.0379
[225/740] Training loss: 0.0050	 Validation loss: 0.0372
[230/740] Training loss: 0.0047	 Validation loss: 0.0364
[235/740] Training loss: 0.0044	 Validation loss: 0.0357
[240/740] Training loss: 0.0042	 Validation loss: 0.0350
[245/740] Training loss: 0.0040	 Validation loss: 0.0344
[250/740] Training loss: 0.0038	 Validation loss: 0.0338
[255/740] Training loss: 0.0036	 Validation loss: 0.0333
[260/740] Training loss: 0.0034	 Validation loss: 0.0327
[265/740] Training loss: 0.0033	 Validation loss: 0.0323
[270/740] Training loss: 0.0031	 Validation loss: 0.0318
[275/740] Training loss: 0.0030	 Validation loss: 0.0314
[280/740] Training loss: 0.0028	 Validation loss: 0.0310
[285/740] Training loss: 0.0027	 Validation loss: 0.0307
[290/740] Training loss: 0.0026	 Validation loss: 0.0304
[295/740] Training loss: 0.0025	 Validation loss: 0.0301
[300/740] Training loss: 0.0024	 Validation loss: 0.0299
[305/740] Training loss: 0.0023	 Validation loss: 0.0297
[310/740] Training loss: 0.0022	 Validation loss: 0.0295
[315/740] Training loss: 0.0022	 Validation loss: 0.0293
[320/740] Training loss: 0.0021	 Validation loss: 0.0292
[325/740] Training loss: 0.0020	 Validation loss: 0.0290
[330/740] Training loss: 0.0019	 Validation loss: 0.0289
[335/740] Training loss: 0.0019	 Validation loss: 0.0288
[340/740] Training loss: 0.0018	 Validation loss: 0.0287
[345/740] Training loss: 0.0017	 Validation loss: 0.0287
[350/740] Training loss: 0.0017	 Validation loss: 0.0286
[355/740] Training loss: 0.0016	 Validation loss: 0.0285
[360/740] Training loss: 0.0016	 Validation loss: 0.0285
[365/740] Training loss: 0.0016	 Validation loss: 0.0284
[370/740] Training loss: 0.0015	 Validation loss: 0.0283
[375/740] Training loss: 0.0015	 Validation loss: 0.0283
[380/740] Training loss: 0.0015	 Validation loss: 0.0282
[385/740] Training loss: 0.0014	 Validation loss: 0.0281
[390/740] Training loss: 0.0014	 Validation loss: 0.0280
[395/740] Training loss: 0.0013	 Validation loss: 0.0279
[400/740] Training loss: 0.0013	 Validation loss: 0.0278
[405/740] Training loss: 0.0013	 Validation loss: 0.0277
[410/740] Training loss: 0.0013	 Validation loss: 0.0277
[415/740] Training loss: 0.0013	 Validation loss: 0.0277
[420/740] Training loss: 0.0013	 Validation loss: 0.0275
[425/740] Training loss: 0.0012	 Validation loss: 0.0273
[430/740] Training loss: 0.0012	 Validation loss: 0.0272
[435/740] Training loss: 0.0011	 Validation loss: 0.0271
[440/740] Training loss: 0.0011	 Validation loss: 0.0271
[445/740] Training loss: 0.0011	 Validation loss: 0.0271
[450/740] Training loss: 0.0012	 Validation loss: 0.0272
[455/740] Training loss: 0.0012	 Validation loss: 0.0276
[460/740] Training loss: 0.0013	 Validation loss: 0.0272
[465/740] Training loss: 0.0011	 Validation loss: 0.0265
[470/740] Training loss: 0.0010	 Validation loss: 0.0263
[475/740] Training loss: 0.0010	 Validation loss: 0.0264
[480/740] Training loss: 0.0010	 Validation loss: 0.0264
[485/740] Training loss: 0.0009	 Validation loss: 0.0264
[490/740] Training loss: 0.0009	 Validation loss: 0.0265
[495/740] Training loss: 0.0009	 Validation loss: 0.0268
[500/740] Training loss: 0.0011	 Validation loss: 0.0273
[505/740] Training loss: 0.0016	 Validation loss: 0.0269
[510/740] Training loss: 0.0011	 Validation loss: 0.0262
[515/740] Training loss: 0.0009	 Validation loss: 0.0260
[520/740] Training loss: 0.0008	 Validation loss: 0.0258
[525/740] Training loss: 0.0008	 Validation loss: 0.0257
[530/740] Training loss: 0.0008	 Validation loss: 0.0258
[535/740] Training loss: 0.0008	 Validation loss: 0.0260
[540/740] Training loss: 0.0010	 Validation loss: 0.0264
[545/740] Training loss: 0.0013	 Validation loss: 0.0263
[550/740] Training loss: 0.0010	 Validation loss: 0.0256
[555/740] Training loss: 0.0008	 Validation loss: 0.0251
[560/740] Training loss: 0.0008	 Validation loss: 0.0249
[565/740] Training loss: 0.0008	 Validation loss: 0.0249
[570/740] Training loss: 0.0007	 Validation loss: 0.0248
[575/740] Training loss: 0.0007	 Validation loss: 0.0252
[580/740] Training loss: 0.0009	 Validation loss: 0.0258
[585/740] Training loss: 0.0012	 Validation loss: 0.0263
[590/740] Training loss: 0.0014	 Validation loss: 0.0257
[595/740] Training loss: 0.0008	 Validation loss: 0.0245
[600/740] Training loss: 0.0007	 Validation loss: 0.0243
[605/740] Training loss: 0.0007	 Validation loss: 0.0243
[610/740] Training loss: 0.0006	 Validation loss: 0.0244
[615/740] Training loss: 0.0006	 Validation loss: 0.0246
[620/740] Training loss: 0.0008	 Validation loss: 0.0250
[625/740] Training loss: 0.0010	 Validation loss: 0.0254
[630/740] Training loss: 0.0011	 Validation loss: 0.0247
[635/740] Training loss: 0.0008	 Validation loss: 0.0240
[640/740] Training loss: 0.0007	 Validation loss: 0.0236
[645/740] Training loss: 0.0007	 Validation loss: 0.0235
[650/740] Training loss: 0.0007	 Validation loss: 0.0236
[655/740] Training loss: 0.0006	 Validation loss: 0.0238
[660/740] Training loss: 0.0006	 Validation loss: 0.0241
[665/740] Training loss: 0.0010	 Validation loss: 0.0252
[670/740] Training loss: 0.0015	 Validation loss: 0.0255
[675/740] Training loss: 0.0010	 Validation loss: 0.0238
[680/740] Training loss: 0.0007	 Validation loss: 0.0234
[685/740] Training loss: 0.0006	 Validation loss: 0.0236
[690/740] Training loss: 0.0006	 Validation loss: 0.0234
[695/740] Training loss: 0.0005	 Validation loss: 0.0234
[700/740] Training loss: 0.0006	 Validation loss: 0.0235
[705/740] Training loss: 0.0007	 Validation loss: 0.0237
[710/740] Training loss: 0.0007	 Validation loss: 0.0236
[715/740] Training loss: 0.0009	 Validation loss: 0.0235
[720/740] Training loss: 0.0009	 Validation loss: 0.0234
[725/740] Training loss: 0.0007	 Validation loss: 0.0230
[730/740] Training loss: 0.0008	 Validation loss: 0.0222
[735/740] Training loss: 0.0010	 Validation loss: 0.0219
[740/740] Training loss: 0.0008	 Validation loss: 0.0224
Bus error (core dumped)
