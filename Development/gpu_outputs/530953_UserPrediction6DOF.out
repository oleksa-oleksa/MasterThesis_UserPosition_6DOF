INFO:root:LSTM Pure PyTorch: hidden_dim: 24, n_epochs: 740, batch_size: 4096.
INFO:root:Trace path: data/flipped/1556.csv
INFO:root:Prediction window = 100.0 ms
INFO:root:MAE position = 0.059461827596028645
INFO:root:MAE rotation = 2.6541692804250125
INFO:root:RMSE position = 0.113827825
INFO:root:RMSE rotation = 3.484436974036349
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/opt/UserPrediction6DOF/__main__.py", line 45, in <module>
    APPLICATION.run()
  File "/opt/UserPrediction6DOF/application.py", line 91, in run
    self.run_lstm()
  File "/opt/UserPrediction6DOF/application.py", line 138, in run_lstm
    runner.run()
  File "/opt/UserPrediction6DOF/runners.py", line 394, in run
    'euc_dists_lstm_{}_{}ms.npy'.format(basename, int(w * 1e3))), euc_dists)
  File "<__array_function__ internals>", line 6, in save
  File "/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py", line 525, in save
    file_ctx = open(file, "wb")
OSError: [Errno 30] Read-only file system: './results/tabular/distances/euc_dists_lstm_1556_100ms.npy'
-------------------------------------------------------------------------
-------------------------------------------------------------------------
X_train (71999, 11), X_val (24000, 11), X_test(24000, 11), y_train (71999, 7), y_val (24000, 7), y_test (24000, 7)
[1/740] Training loss: 5.0466	 Validation loss: 2.8008
[2/740] Training loss: 4.9326	 Validation loss: 2.7249
[3/740] Training loss: 4.8163	 Validation loss: 2.6442
[4/740] Training loss: 4.6905	 Validation loss: 2.5554
[5/740] Training loss: 4.5503	 Validation loss: 2.4562
[10/740] Training loss: 3.5845	 Validation loss: 1.8118
[15/740] Training loss: 2.4780	 Validation loss: 1.1664
[20/740] Training loss: 1.6179	 Validation loss: 0.7415
[25/740] Training loss: 1.0760	 Validation loss: 0.5131
[30/740] Training loss: 0.7575	 Validation loss: 0.4016
[35/740] Training loss: 0.5704	 Validation loss: 0.3549
[40/740] Training loss: 0.4508	 Validation loss: 0.3290
[45/740] Training loss: 0.3614	 Validation loss: 0.2998
[50/740] Training loss: 0.2883	 Validation loss: 0.2659
[55/740] Training loss: 0.2298	 Validation loss: 0.2346
[60/740] Training loss: 0.1845	 Validation loss: 0.2081
[65/740] Training loss: 0.1500	 Validation loss: 0.1858
[70/740] Training loss: 0.1235	 Validation loss: 0.1667
[75/740] Training loss: 0.1029	 Validation loss: 0.1500
[80/740] Training loss: 0.0867	 Validation loss: 0.1353
[85/740] Training loss: 0.0739	 Validation loss: 0.1224
[90/740] Training loss: 0.0636	 Validation loss: 0.1113
[95/740] Training loss: 0.0553	 Validation loss: 0.1017
[100/740] Training loss: 0.0485	 Validation loss: 0.0935
[105/740] Training loss: 0.0428	 Validation loss: 0.0864
[110/740] Training loss: 0.0380	 Validation loss: 0.0804
[115/740] Training loss: 0.0340	 Validation loss: 0.0752
[120/740] Training loss: 0.0305	 Validation loss: 0.0708
[125/740] Training loss: 0.0275	 Validation loss: 0.0669
[130/740] Training loss: 0.0249	 Validation loss: 0.0636
[135/740] Training loss: 0.0226	 Validation loss: 0.0607
[140/740] Training loss: 0.0206	 Validation loss: 0.0582
[145/740] Training loss: 0.0188	 Validation loss: 0.0560
[150/740] Training loss: 0.0172	 Validation loss: 0.0541
[155/740] Training loss: 0.0158	 Validation loss: 0.0524
[160/740] Training loss: 0.0145	 Validation loss: 0.0508
[165/740] Training loss: 0.0133	 Validation loss: 0.0494
[170/740] Training loss: 0.0123	 Validation loss: 0.0481
[175/740] Training loss: 0.0114	 Validation loss: 0.0469
[180/740] Training loss: 0.0106	 Validation loss: 0.0458
[185/740] Training loss: 0.0098	 Validation loss: 0.0447
[190/740] Training loss: 0.0091	 Validation loss: 0.0437
[195/740] Training loss: 0.0085	 Validation loss: 0.0428
[200/740] Training loss: 0.0079	 Validation loss: 0.0419
[205/740] Training loss: 0.0074	 Validation loss: 0.0410
[210/740] Training loss: 0.0069	 Validation loss: 0.0402
[215/740] Training loss: 0.0065	 Validation loss: 0.0394
[220/740] Training loss: 0.0061	 Validation loss: 0.0387
[225/740] Training loss: 0.0057	 Validation loss: 0.0380
[230/740] Training loss: 0.0054	 Validation loss: 0.0373
[235/740] Training loss: 0.0050	 Validation loss: 0.0367
[240/740] Training loss: 0.0048	 Validation loss: 0.0360
[245/740] Training loss: 0.0045	 Validation loss: 0.0355
[250/740] Training loss: 0.0042	 Validation loss: 0.0349
[255/740] Training loss: 0.0040	 Validation loss: 0.0344
[260/740] Training loss: 0.0038	 Validation loss: 0.0339
[265/740] Training loss: 0.0036	 Validation loss: 0.0334
[270/740] Training loss: 0.0034	 Validation loss: 0.0330
[275/740] Training loss: 0.0032	 Validation loss: 0.0325
[280/740] Training loss: 0.0031	 Validation loss: 0.0321
[285/740] Training loss: 0.0029	 Validation loss: 0.0317
[290/740] Training loss: 0.0028	 Validation loss: 0.0314
[295/740] Training loss: 0.0027	 Validation loss: 0.0310
[300/740] Training loss: 0.0026	 Validation loss: 0.0307
[305/740] Training loss: 0.0025	 Validation loss: 0.0303
[310/740] Training loss: 0.0024	 Validation loss: 0.0300
[315/740] Training loss: 0.0023	 Validation loss: 0.0297
[320/740] Training loss: 0.0022	 Validation loss: 0.0294
[325/740] Training loss: 0.0021	 Validation loss: 0.0291
[330/740] Training loss: 0.0020	 Validation loss: 0.0288
[335/740] Training loss: 0.0019	 Validation loss: 0.0285
[340/740] Training loss: 0.0019	 Validation loss: 0.0283
[345/740] Training loss: 0.0018	 Validation loss: 0.0280
[350/740] Training loss: 0.0018	 Validation loss: 0.0277
[355/740] Training loss: 0.0017	 Validation loss: 0.0274
[360/740] Training loss: 0.0016	 Validation loss: 0.0272
[365/740] Training loss: 0.0016	 Validation loss: 0.0269
[370/740] Training loss: 0.0015	 Validation loss: 0.0266
[375/740] Training loss: 0.0015	 Validation loss: 0.0264
[380/740] Training loss: 0.0014	 Validation loss: 0.0261
[385/740] Training loss: 0.0014	 Validation loss: 0.0259
[390/740] Training loss: 0.0014	 Validation loss: 0.0257
[395/740] Training loss: 0.0013	 Validation loss: 0.0254
[400/740] Training loss: 0.0013	 Validation loss: 0.0252
[405/740] Training loss: 0.0013	 Validation loss: 0.0250
[410/740] Training loss: 0.0012	 Validation loss: 0.0248
[415/740] Training loss: 0.0012	 Validation loss: 0.0246
[420/740] Training loss: 0.0012	 Validation loss: 0.0244
[425/740] Training loss: 0.0012	 Validation loss: 0.0242
[430/740] Training loss: 0.0011	 Validation loss: 0.0240
[435/740] Training loss: 0.0011	 Validation loss: 0.0238
[440/740] Training loss: 0.0011	 Validation loss: 0.0236
[445/740] Training loss: 0.0011	 Validation loss: 0.0234
[450/740] Training loss: 0.0010	 Validation loss: 0.0233
[455/740] Training loss: 0.0011	 Validation loss: 0.0232
[460/740] Training loss: 0.0011	 Validation loss: 0.0231
[465/740] Training loss: 0.0010	 Validation loss: 0.0227
[470/740] Training loss: 0.0009	 Validation loss: 0.0223
[475/740] Training loss: 0.0009	 Validation loss: 0.0219
[480/740] Training loss: 0.0009	 Validation loss: 0.0216
[485/740] Training loss: 0.0010	 Validation loss: 0.0213
[490/740] Training loss: 0.0011	 Validation loss: 0.0214
[495/740] Training loss: 0.0010	 Validation loss: 0.0217
[500/740] Training loss: 0.0009	 Validation loss: 0.0220
[505/740] Training loss: 0.0010	 Validation loss: 0.0222
[510/740] Training loss: 0.0010	 Validation loss: 0.0219
[515/740] Training loss: 0.0008	 Validation loss: 0.0213
[520/740] Training loss: 0.0007	 Validation loss: 0.0210
[525/740] Training loss: 0.0007	 Validation loss: 0.0208
[530/740] Training loss: 0.0007	 Validation loss: 0.0208
[535/740] Training loss: 0.0007	 Validation loss: 0.0208
[540/740] Training loss: 0.0008	 Validation loss: 0.0213
[545/740] Training loss: 0.0012	 Validation loss: 0.0217
[550/740] Training loss: 0.0011	 Validation loss: 0.0208
[555/740] Training loss: 0.0008	 Validation loss: 0.0200
[560/740] Training loss: 0.0007	 Validation loss: 0.0194
[565/740] Training loss: 0.0008	 Validation loss: 0.0193
[570/740] Training loss: 0.0008	 Validation loss: 0.0194
[575/740] Training loss: 0.0007	 Validation loss: 0.0196
[580/740] Training loss: 0.0008	 Validation loss: 0.0202
[585/740] Training loss: 0.0009	 Validation loss: 0.0204
[590/740] Training loss: 0.0009	 Validation loss: 0.0198
[595/740] Training loss: 0.0007	 Validation loss: 0.0190
[600/740] Training loss: 0.0006	 Validation loss: 0.0185
[605/740] Training loss: 0.0006	 Validation loss: 0.0184
[610/740] Training loss: 0.0006	 Validation loss: 0.0184
[615/740] Training loss: 0.0006	 Validation loss: 0.0186
[620/740] Training loss: 0.0006	 Validation loss: 0.0192
[625/740] Training loss: 0.0011	 Validation loss: 0.0200
[630/740] Training loss: 0.0011	 Validation loss: 0.0196
[635/740] Training loss: 0.0010	 Validation loss: 0.0188
[640/740] Training loss: 0.0007	 Validation loss: 0.0177
[645/740] Training loss: 0.0008	 Validation loss: 0.0174
[650/740] Training loss: 0.0008	 Validation loss: 0.0177
[655/740] Training loss: 0.0006	 Validation loss: 0.0179
[660/740] Training loss: 0.0006	 Validation loss: 0.0183
[665/740] Training loss: 0.0007	 Validation loss: 0.0183
[670/740] Training loss: 0.0006	 Validation loss: 0.0177
[675/740] Training loss: 0.0005	 Validation loss: 0.0170
[680/740] Training loss: 0.0005	 Validation loss: 0.0166
[685/740] Training loss: 0.0006	 Validation loss: 0.0164
[690/740] Training loss: 0.0006	 Validation loss: 0.0165
[695/740] Training loss: 0.0006	 Validation loss: 0.0168
[700/740] Training loss: 0.0008	 Validation loss: 0.0178
[705/740] Training loss: 0.0008	 Validation loss: 0.0187
[710/740] Training loss: 0.0013	 Validation loss: 0.0193
[715/740] Training loss: 0.0013	 Validation loss: 0.0181
[720/740] Training loss: 0.0007	 Validation loss: 0.0170
[725/740] Training loss: 0.0006	 Validation loss: 0.0167
[730/740] Training loss: 0.0005	 Validation loss: 0.0166
[735/740] Training loss: 0.0004	 Validation loss: 0.0167
[740/740] Training loss: 0.0005	 Validation loss: 0.0167
