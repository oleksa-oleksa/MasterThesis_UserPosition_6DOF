python -m UserPrediction6DOF run -a rnn -m lstm -w 100 -d data/flipped
INFO:root:Model LSTM with Sliding Window on GPU with cuda: False
INFO:root:RNN model is LSTM with Sliding Window: hidden_dim: 32, batch_size: 256, n_epochs: 1500, dropout: 0, layers: 1, window: 100.0, LR: 0.001
INFO:root:-------------------------------------------------------------------------
INFO:root:Trace path: data/flipped/1556.csv
INFO:root:-------------------------------------------------------------------------
X.shape: (120019, 10)
len(X): 120019
Past 60 values for predict in 20 in future
y.shape: (120019, 7)
X_w.shape: (119940, 60, 10)
y_w.shape: (119940, 1, 7)
INFO:root:X_train (71964, 60, 10), X_val (23988, 60, 10), X_test(23988, 60, 10), y_train (71964, 1, 7), y_val (23988, 1, 7), y_test (23988, 1, 7)
INFO:root:[1/1500] Training loss: 3.0545	 Validation loss: 0.7517
INFO:root:[2/1500] Training loss: 0.8181	 Validation loss: 0.4426
INFO:root:[3/1500] Training loss: 0.3551	 Validation loss: 0.4543
INFO:root:[4/1500] Training loss: 0.1943	 Validation loss: 0.2473
INFO:root:[5/1500] Training loss: 0.1313	 Validation loss: 0.1917
INFO:root:[10/1500] Training loss: 0.0314	 Validation loss: 0.1163
INFO:root:[15/1500] Training loss: 0.0359	 Validation loss: 0.1026
INFO:root:[20/1500] Training loss: 0.0308	 Validation loss: 0.2077
INFO:root:[25/1500] Training loss: 0.0103	 Validation loss: 0.0855
Learning rate is 0.0003
INFO:root:[30/1500] Training loss: 0.0453	 Validation loss: 0.1341
INFO:root:[35/1500] Training loss: 0.0041	 Validation loss: 0.0351
INFO:root:[40/1500] Training loss: 0.0030	 Validation loss: 0.0322
INFO:root:[45/1500] Training loss: 0.0026	 Validation loss: 0.0307
INFO:root:[50/1500] Training loss: 0.0071	 Validation loss: 0.0570
INFO:root:[55/1500] Training loss: 0.0035	 Validation loss: 0.0326
Learning rate is 8.999999999999999e-05
INFO:root:[60/1500] Training loss: 0.0038	 Validation loss: 0.0248
INFO:root:[65/1500] Training loss: 0.0019	 Validation loss: 0.0199
INFO:root:[70/1500] Training loss: 0.0018	 Validation loss: 0.0196
INFO:root:[75/1500] Training loss: 0.0018	 Validation loss: 0.0187
INFO:root:[80/1500] Training loss: 0.0017	 Validation loss: 0.0177
INFO:root:[85/1500] Training loss: 0.0017	 Validation loss: 0.0179
Learning rate is 2.6999999999999996e-05
INFO:root:[90/1500] Training loss: 0.0017	 Validation loss: 0.0174
INFO:root:[95/1500] Training loss: 0.0016	 Validation loss: 0.0174
INFO:root:[100/1500] Training loss: 0.0016	 Validation loss: 0.0174
INFO:root:[105/1500] Training loss: 0.0016	 Validation loss: 0.0173
INFO:root:[110/1500] Training loss: 0.0016	 Validation loss: 0.0171
INFO:root:[115/1500] Training loss: 0.0016	 Validation loss: 0.0170
Learning rate is 8.099999999999999e-06
INFO:root:[120/1500] Training loss: 0.0016	 Validation loss: 0.0169
INFO:root:[125/1500] Training loss: 0.0016	 Validation loss: 0.0167
INFO:root:[130/1500] Training loss: 0.0016	 Validation loss: 0.0167
INFO:root:[135/1500] Training loss: 0.0015	 Validation loss: 0.0166
INFO:root:[140/1500] Training loss: 0.0015	 Validation loss: 0.0166
INFO:root:[145/1500] Training loss: 0.0015	 Validation loss: 0.0165
Learning rate is 2.4299999999999996e-06
INFO:root:[150/1500] Training loss: 0.0015	 Validation loss: 0.0165
INFO:root:[155/1500] Training loss: 0.0015	 Validation loss: 0.0165
INFO:root:[160/1500] Training loss: 0.0015	 Validation loss: 0.0165
INFO:root:[165/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[170/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[175/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 7.289999999999998e-07
INFO:root:[180/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[185/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[190/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[195/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[200/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[205/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 2.1869999999999994e-07
INFO:root:[210/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[215/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[220/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[225/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[230/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[235/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 6.560999999999998e-08
INFO:root:[240/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[245/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[250/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[255/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[260/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[265/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 1.9682999999999992e-08
INFO:root:[270/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[275/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[280/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[285/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[290/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[295/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 5.904899999999998e-09
INFO:root:[300/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[305/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[310/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[315/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[320/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[325/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 1.7714699999999993e-09
INFO:root:[330/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[335/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[340/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[345/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[350/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[355/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 5.314409999999998e-10
INFO:root:[360/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[365/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[370/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[375/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[380/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[385/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 1.5943229999999992e-10
INFO:root:[390/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[395/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[400/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[405/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[410/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[415/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 4.7829689999999974e-11
INFO:root:[420/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[425/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[430/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[435/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[440/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[445/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 1.4348906999999992e-11
INFO:root:[450/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[455/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[460/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[465/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[470/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[475/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 4.304672099999997e-12
INFO:root:[480/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[485/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[490/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[495/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[500/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[505/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 1.291401629999999e-12
INFO:root:[510/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[515/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[520/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[525/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[530/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[535/1500] Training loss: 0.0015	 Validation loss: 0.0164
Learning rate is 3.874204889999997e-13
INFO:root:[540/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[545/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[550/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[555/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[560/1500] Training loss: 0.0015	 Validation loss: 0.0164
INFO:root:[565/1500] Training loss: 0.0015	 Validation loss: 0.0164

-------------------------------------------------------------------
-------------------------------------------------------------------
python -m UserPrediction6DOF run -a rnn -m lstm -w 100 -d data/flipped
INFO:root:Model LSTM with Sliding Window on GPU with cuda: False
INFO:root:RNN model is LSTM with Sliding Window: hidden_dim: 32, batch_size: 256, n_epochs: 500, dropout: 0, layers: 1, window: 100.0, LR: 0.01
INFO:root:-------------------------------------------------------------------------
INFO:root:Trace path: data/flipped/1556.csv
INFO:root:-------------------------------------------------------------------------
X.shape: (120019, 10)
len(X): 120019
Past 60 values for predict in 20 in future
y.shape: (120019, 7)
X_w.shape: (119940, 60, 10)
y_w.shape: (119940, 1, 7)
INFO:root:X_train (71964, 60, 10), X_val (23988, 60, 10), X_test(23988, 60, 10), y_train (71964, 1, 7), y_val (23988, 1, 7), y_test (23988, 1, 7)
INFO:root:[1/500] Training loss: 1.8481	 Validation loss: 2.7696
INFO:root:[2/500] Training loss: 0.9467	 Validation loss: 0.9728
INFO:root:[3/500] Training loss: 0.2868	 Validation loss: 0.7935
INFO:root:[4/500] Training loss: 0.1868	 Validation loss: 0.4025
INFO:root:[5/500] Training loss: 0.1733	 Validation loss: 0.8683
INFO:root:[10/500] Training loss: 0.1537	 Validation loss: 0.3493
INFO:root:[15/500] Training loss: 0.1782	 Validation loss: 0.3276
INFO:root:[20/500] Training loss: 0.2494	 Validation loss: 0.5733
INFO:root:[25/500] Training loss: 0.0977	 Validation loss: 0.1732
Learning rate is 0.003
INFO:root:[30/500] Training loss: 0.0891	 Validation loss: 0.2242
INFO:root:[35/500] Training loss: 0.0124	 Validation loss: 0.0734
INFO:root:[40/500] Training loss: 0.0088	 Validation loss: 0.0685
INFO:root:[45/500] Training loss: 0.0085	 Validation loss: 0.0606
INFO:root:[50/500] Training loss: 0.0134	 Validation loss: 0.0749
INFO:root:[55/500] Training loss: 0.0206	 Validation loss: 0.0973
Learning rate is 0.0009
INFO:root:[60/500] Training loss: 0.0141	 Validation loss: 0.0933
INFO:root:[65/500] Training loss: 0.0042	 Validation loss: 0.0564
INFO:root:[70/500] Training loss: 0.0036	 Validation loss: 0.0497
INFO:root:[75/500] Training loss: 0.0041	 Validation loss: 0.0551
INFO:root:[80/500] Training loss: 0.0035	 Validation loss: 0.0448
INFO:root:[85/500] Training loss: 0.0035	 Validation loss: 0.0499
Learning rate is 0.00027
INFO:root:[90/500] Training loss: 0.0033	 Validation loss: 0.0400
INFO:root:[95/500] Training loss: 0.0024	 Validation loss: 0.0389
INFO:root:[100/500] Training loss: 0.0023	 Validation loss: 0.0385
INFO:root:[105/500] Training loss: 0.0023	 Validation loss: 0.0381
INFO:root:[110/500] Training loss: 0.0022	 Validation loss: 0.0377
INFO:root:[115/500] Training loss: 0.0021	 Validation loss: 0.0376
Learning rate is 8.1e-05
INFO:root:[120/500] Training loss: 0.0021	 Validation loss: 0.0371
INFO:root:[125/500] Training loss: 0.0020	 Validation loss: 0.0375
INFO:root:[130/500] Training loss: 0.0020	 Validation loss: 0.0373
INFO:root:[135/500] Training loss: 0.0020	 Validation loss: 0.0371
INFO:root:[140/500] Training loss: 0.0020	 Validation loss: 0.0369
INFO:root:[145/500] Training loss: 0.0019	 Validation loss: 0.0367
Learning rate is 2.43e-05
INFO:root:[150/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[155/500] Training loss: 0.0019	 Validation loss: 0.0369
INFO:root:[160/500] Training loss: 0.0019	 Validation loss: 0.0369
INFO:root:[165/500] Training loss: 0.0019	 Validation loss: 0.0368
INFO:root:[170/500] Training loss: 0.0019	 Validation loss: 0.0368
INFO:root:[175/500] Training loss: 0.0019	 Validation loss: 0.0367
Learning rate is 7.29e-06
INFO:root:[180/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[185/500] Training loss: 0.0019	 Validation loss: 0.0367
INFO:root:[190/500] Training loss: 0.0019	 Validation loss: 0.0367
INFO:root:[195/500] Training loss: 0.0019	 Validation loss: 0.0367
INFO:root:[200/500] Training loss: 0.0019	 Validation loss: 0.0367
INFO:root:[205/500] Training loss: 0.0019	 Validation loss: 0.0367
Learning rate is 2.187e-06
INFO:root:[210/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[215/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[220/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[225/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[230/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[235/500] Training loss: 0.0019	 Validation loss: 0.0366
Learning rate is 6.561e-07
INFO:root:[240/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[245/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[250/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[255/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[260/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[265/500] Training loss: 0.0019	 Validation loss: 0.0366
Learning rate is 1.9682999999999997e-07
INFO:root:[270/500] Training loss: 0.0019	 Validation loss: 0.0366
INFO:root:[275/500] Training loss: 0.0019	 Validation loss: 0.0366
^CTraceback (most recent call last):
  File "/Users/oleksandra/.pyenv/versions/3.8.1/lib/python3.8/runpy.py", line 193, in _run_module_as_main
    return _run_code(code, main_globals, None,


------------------------------------------------------------

INFO:root:RNN model is LSTM with Sliding Window: hidden_dim: 32, batch_size: 256, n_epochs: 500, dropout: 0, layers: 1, window: 100.0, LR: 1e-08
INFO:root:-------------------------------------------------------------------------
INFO:root:Trace path: data/flipped/1556.csv
INFO:root:-------------------------------------------------------------------------
X.shape: (120019, 11)
len(X): 120019
Past 60 values for predict in 20 in future
y.shape: (120019, 7)
X_w.shape: (119940, 60, 11)
y_w.shape: (119940, 1, 7)
INFO:root:X_train (71964, 60, 11), X_val (23988, 60, 11), X_test(23988, 60, 11), y_train (71964, 1, 7), y_val (23988, 1, 7), y_test (23988, 1, 7)
INFO:root:[1/500] Training loss: 4.8682	 Validation loss: 3.4019
INFO:root:[2/500] Training loss: 4.8682	 Validation loss: 3.4018
INFO:root:[3/500] Training loss: 4.8681	 Validation loss: 3.4018
INFO:root:[4/500] Training loss: 4.8681	 Validation loss: 3.4018
INFO:root:[5/500] Training loss: 4.8681	 Validation loss: 3.4018

